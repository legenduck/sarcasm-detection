{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detection in News Headlines: Full Pipeline Demo\n",
    "\n",
    "**Author:** Deogyong Kim (2021134015)\n",
    "\n",
    "This notebook demonstrates a complete pipeline for detecting sarcasm in news headlines, comparing five different approaches:\n",
    "1. Naive Baseline (rule-based)\n",
    "2. Embedding + Centroid\n",
    "3. Embedding + Logistic Regression\n",
    "4. LLM Zero-shot\n",
    "5. LLM Few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
      "Requirement already satisfied: transformers==4.51.3 in /usr/local/lib/python3.10/dist-packages (4.51.3)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
      "Requirement already satisfied: autoawq in /usr/local/lib/python3.10/dist-packages (0.2.9)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (2.11.0)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.36.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.21.0) (10.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.3) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.3) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.3) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.51.3) (0.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: datasets>=2.20 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.4.1)\n",
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20->autoawq) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20->autoawq) (0.4.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20->autoawq) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.20->autoawq) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (3.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.20->autoawq) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.51.3) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.51.3) (2.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.6.0) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mAll packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib seaborn tqdm torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 transformers==4.51.3 sentence-transformers accelerate autoawq openai huggingface_hub\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python version: 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "\n",
      " Model already exists at /root/model/Qwen2.5-32B-Instruct-AWQ\n",
      "\n",
      " Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# Verify installations\n",
    "import sys\n",
    "import torch\n",
    "print(f\"\\nPython version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Download Qwen model if not exists\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path.home() / \"model\"\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-32B-Instruct-AWQ\"\n",
    "LOCAL_MODEL_PATH = MODEL_DIR / \"Qwen2.5-32B-Instruct-AWQ\"\n",
    "\n",
    "if not LOCAL_MODEL_PATH.exists():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"Downloading Qwen2.5-32B-Instruct-AWQ model...\")\n",
    "    print(f\"This will take a while (~20 GB download)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    from huggingface_hub import snapshot_download\n",
    "    \n",
    "    snapshot_download(\n",
    "        repo_id=MODEL_NAME,\n",
    "        local_dir=str(LOCAL_MODEL_PATH),\n",
    "        local_dir_use_symlinks=False,\n",
    "        resume_download=True\n",
    "    )\n",
    "    print(f\"\\n Model downloaded to {LOCAL_MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"\\n Model already exists at {LOCAL_MODEL_PATH}\")\n",
    "\n",
    "print(\"\\n Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded\n",
      "  Random seed: 42\n",
      "  Test size: 0.2\n",
      "  Embedding model: all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_FILE = \"../data/Sarcasm_Headlines_Dataset_v2.json\"\n",
    "RESULTS_DIR = \"../results\"\n",
    "\n",
    "# LLM API\n",
    "LLM_API_BASE = \"http://localhost:8000/v1\"\n",
    "LLM_API_KEY = \"EMPTY\"\n",
    "\n",
    "# Experiment settings\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "EMBEDDING_MODEL = \"all-mpnet-base-v2\"\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(f\"Configuration loaded\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "print(f\"  Test size: {TEST_SIZE}\")\n",
    "print(f\"  Embedding model: {EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset found at ../data/Sarcasm_Headlines_Dataset_v2.json\n",
      "Dataset shape: (28619, 3)\n",
      "\n",
      "Columns: ['is_sarcastic', 'headline', 'article_link']\n",
      "\n",
      "Class distribution:\n",
      "is_sarcastic\n",
      "0    14985\n",
      "1    13634\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class percentages:\n",
      "is_sarcastic\n",
      "0    52.36032\n",
      "1    47.63968\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3. Load and Explore Data\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Check if dataset exists, if not download from Kaggle\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    print(f\"Dataset not found at {DATA_FILE}\")\n",
    "    print(\"Downloading from Kaggle...\")\n",
    "    \n",
    "    !pip install -q kagglehub\n",
    "    import kagglehub\n",
    "    \n",
    "    # Download dataset\n",
    "    path = kagglehub.dataset_download(\"rmisra/news-headlines-dataset-for-sarcasm-detection\")\n",
    "    print(f\"Downloaded to: {path}\")\n",
    "    \n",
    "    # Find and move the JSON file\n",
    "    os.makedirs(os.path.dirname(DATA_FILE), exist_ok=True)\n",
    "    downloaded_file = os.path.join(path, \"Sarcasm_Headlines_Dataset_v2.json\")\n",
    "    shutil.copy(downloaded_file, DATA_FILE)\n",
    "    print(f\"✓ Dataset copied to {DATA_FILE}\")\n",
    "else:\n",
    "    print(f\"✓ Dataset found at {DATA_FILE}\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_json(DATA_FILE, lines=True)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['is_sarcastic'].value_counts())\n",
    "print(f\"\\nClass percentages:\")\n",
    "print(df['is_sarcastic'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample REAL headlines:\n",
      "  • dem rep. totally nails why congress is falling short on gender, racial equality\n",
      "  • eat your veggies: 9 deliciously different recipes\n",
      "  • my white inheritance\n",
      "  • 5 ways to file your taxes with less stress\n",
      "  • lots of parents know this scenario\n",
      "\n",
      "Sample SATIRE headlines:\n",
      "  • thirtysomething scientists unveil doomsday clock of hair loss\n",
      "  • inclement weather prevents liar from getting to work\n",
      "  • mother comes pretty close to using word 'streaming' correctly\n",
      "  • richard branson's global-warming donation nearly as much as cost of failed balloon trips\n",
      "  • shadow government getting too large to meet in marriott conference room b\n"
     ]
    }
   ],
   "source": [
    "# Display sample headlines\n",
    "print(\"Sample REAL headlines:\")\n",
    "for headline in df[df['is_sarcastic'] == 0]['headline'].head(5):\n",
    "    print(f\"  • {headline}\")\n",
    "\n",
    "print(\"\\nSample SATIRE headlines:\")\n",
    "for headline in df[df['is_sarcastic'] == 1]['headline'].head(5):\n",
    "    print(f\"  • {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAHaCAYAAACQINBuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWo0lEQVR4nOzdd3RU1fr/8c+k0VIghRqaQAIIgVCMhCCKgJcqARURpBgFC0UFKQEhSElA8AcIVxAxFBHkSlEULGC5YEIRgRApSgejkCIEQkmb3x98mcuQBDJxkhmS92utLHP22bPPcx5mHc882bOPwWg0GgUAAAAAAAAAsBsOtg4AAAAAAAAAAGCOwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi2Ae87YsWPVrl07szZ/f3+9++67pu1169bJ399fZ8+eLerw7llnz56Vv7+/lixZUmTHLMp/p9vfN0V9vu+++678/f2L5FgAAKB44L63cPzT+8CbOT9w4ICVIyu4m+e0bt06W4cCwIoo3ALI1d1uRp599ll17dq1iKO6N9h7bn788Uezm31r2blzp/z9/U0/jRo1UnBwsJ599lktXLhQKSkpVjnO1atX9e6772rnzp1WGc+a7Dk2AACQO+57C87ec1NY971FbefOnRo6dKhat26tRo0aqVWrVnrxxRf1zTff2Do0AIWMwi2AYunxxx9XXFycqlWrZutQ7M6PP/6o+fPnF9r4zz77rGbOnKkpU6YoLCxMHh4eevfdd9WpUyfFxsaa9S3Iv9PVq1c1f/587dq1y6K4pkyZoq+++sqi11jqTrG99NJLiouLK9TjAwCAkof73rwV9n1vUZg3b5769++v33//Xb1791ZERITCwsKUlpamYcOGaePGjbYOEUAhcrJ1AABQGBwdHeXo6GjrMEqkFi1a6F//+pdZ2+HDh/Xcc89p+PDh+vLLL1WxYkVJRfPvdOXKFZUtW1bOzs6Fepy7cXJykpMT/9sFAADWxX1v8fXVV19pwYIFeuyxxzR79myz+9nnn39e27ZtU2Zmpg0jBFDYmHELwKo+++wz9ezZUwEBAXrggQf02muv6c8//zTr8/PPP2v48OF6+OGH1ahRI7Vt21bTp0/XtWvXcoy3ZcsWde3aVY0bN1bXrl317bff5iuO3Nb6ateunYYMGaKff/5ZTzzxhBo3bqxHH31UGzZsyPH61NRUTZs2TW3btlWjRo3UoUMHvf/++8rOzrYsIXfw448/6plnnlHTpk0VGBiowYMH6/fffzfrM3bsWAUGBurcuXN6+eWXFRgYqAcffFAzZsxQVlaWWd+///5bb7zxhpo1a6YWLVpozJgxOnz4sNlaV2PHjtXKlSslyWxZg9t98sknat++vRo1aqRevXr945mi9evXV3h4uFJTU03Hl3L/dzpw4IDCwsIUFBSkgIAAtWvXTuPGjZN0Y+2uVq1aSZLmz59viv/mV+Bu5uv06dN64YUXFBgYqFGjRpn23b5G3E1Lly7VI488ooCAAPXr10+//fab2f5nn31Wzz77bI7X3Trm3WLLbY3bzMxMLViwwJTrdu3a6Z133lF6erpZP0veuwAAoGhw35t/xfW+99q1a5o4caKCgoLUrFkzjR49WhcvXjTtHzNmjIKCgpSRkZHjtc8995wee+yxO44/d+5clS9fXtOnT891EkKbNm30yCOP5Pn6w4cPa+zYsXr00UfVuHFjtW7dWuPGjdPff/9t1u/y5cuaNm2a2rVrZ1qKYdCgQfr1119NfU6ePKlhw4apdevWaty4sR566CG99tprunTp0h3PAcA/w9QfAHd0+fLlXNcmze3m47333tPcuXPVqVMnPfHEE0pJSdFHH32kvn37asOGDXJ3d5d04y/H165dU58+fVS+fHnFxcXpo48+0l9//aV58+aZxtu+fbuGDRumunXrauTIkfr77781btw4Va5cucDnc+rUKY0YMUJPPPGEQkNDtXbtWo0dO1b333+/6tWrJ+nG19379eunc+fO6emnn1aVKlW0d+9evfPOO0pMTNT48eMLfPybNmzYoLFjxyokJESjRo3S1atXtWrVKj3zzDNav369fH19TX2zsrIUFhamgIAAjR49WrGxsfrwww9VvXp1PfPMM5Kk7Oxs01fx+/Tpo/vuu09bt27VmDFjzI7bu3dvnT9/Xj/99JNmzpyZa2xffPGF0tLS1Lt3bxkMBn3wwQcaNmyYtmzZ8o9mrT722GMaP368tm/frtdeey3XPsnJyQoLC1OFChU0ePBgubu76+zZs6YPLp6enoqIiFBERIQ6dOigDh06SJLZTXhmZqbCwsLUvHlzjRkzRqVLl75jXBs2bFBaWpqeeeYZXb9+XStWrNCAAQO0ceNGeXt75/v88hPb7SZMmKD169frscce06BBgxQXF6dFixbp2LFjWrBggVnf/Lx3AQBAwXHfy32vpfe9b731ltzd3TV06FCdOHFCq1atUkJCglasWCGDwaDHH39cGzZs0Pbt280KrImJidqxY4deeeWVPMc+efKkjh8/rl69esnV1fWuseQmJiZGZ86cUc+ePeXj46Pff/9da9as0dGjR7VmzRoZDAZJ0qRJk/T111+rX79+qlOnji5cuKA9e/bo2LFjuv/++5Wenq6wsDClp6erX79+8vb21rlz5/TDDz8oNTVVbm5uBYoPQD4YASAXa9euNfr5+d3xp0uXLqb+Z8+eNTZo0MD43nvvmY1z5MgRY8OGDc3ar169muN4ixYtMvr7+xv/+OMPU9vjjz9ubN26tTE1NdXUtn37dqOfn5/xkUceMXu9n5+fcd68eTniP3PmjKntkUceMfr5+Rl3795taktOTjY2atTIGBUVZWpbsGCBsWnTpsYTJ06YHWPWrFnGBg0aGBMSEvLMm9FoNPbr188sN7e7fPmysUWLFsYJEyaYtScmJhqbN29u1j5mzBijn5+fcf78+WZ9e/ToYQwNDTVtf/3110Y/Pz/j0qVLTW1ZWVnG/v37G/38/Ixr1641tU+ePNno5+eXI64zZ84Y/fz8jA888IDxwoULpvYtW7YY/fz8jN99990dz3vHjh1GPz8/4+bNm/Ps0717d2PLli1N27f/O3377bdGPz8/Y1xcXJ5jJCcn5/j3vulmvmbNmpXrvlvfNzfPNyAgwPjXX3+Z2vfv32/08/MzTp8+3dTWr18/Y79+/e465p1imzdvnlneDx06ZPTz8zOOHz/erF9UVJTRz8/PGBsba2rL73sXAABYjvte7ntvyu99782ch4aGGtPT003tixcvNvr5+Rm3bNliiuuhhx4yvvrqq2avj46ONvr7+xtPnz6d5zFuxhIdHX3HWG4/p1vPP7f33xdffJHjvdG8eXPj5MmT8xz74MGDd73PB1A4WCoBwB1NnDhR0dHROX5un0X47bffKjs7W506dVJKSorpx9vbWzVr1tTOnTtNfW+dAXnlyhWlpKQoMDBQRqNRBw8elCSdP39ehw4dUmhoqNlfcFu3bq26desW+Hzq1q2rFi1amLY9PT1Vu3ZtnTlzxtT21VdfqXnz5nJ3dzc7l+DgYGVlZWn37t0FPr504y/fqamp6tKli9n4Dg4OatKkiVmuburTp4/ZdvPmzc2+Drdt2zY5OzvrqaeeMrU5ODiob9++FsfXuXNneXh4mLZv5uvWHBVU2bJllZaWluf+m//WP/zwQ66zW/Lr9nzdSfv27VWpUiXTdkBAgJo0aaIff/yxwMfPj5vjDxo0yKz9ueeeM9t/U37euwAAoOC47+W+19L73t69e5vNzO3Tp4+cnJxM93EODg7q1q2bvvvuO12+fNnU7/PPP1dgYKCqV6+e59g3+5crVy7/J3SbW99/169fV0pKipo0aSJJZssguLu7a//+/Tp37lyu49yc8bt9+3ZdvXq1wPEAsBxLJQC4o4CAADVu3DhHu4eHh9naSCdPnpTRaFTHjh1zHefWhzIlJCRo3rx5+u6778zWgJL+d4OSkJAgSapZs2aOsWrXrm260bVUlSpVcrR5eHiYxXHq1CkdOXLEtF7p7XL7Cp0lTp48KUkaMGBArvtv/ypUqVKl5OnpadZ2e8wJCQny8fFRmTJlzPrVqFHD4vhuz9HNm9nU1FSLx7rdlStX7njz+cADD+ixxx7T/PnztXTpUj3wwANq3769unXrJhcXl3wdw8nJyaKvFeb2HqtVq5Y2b96c7zEK4o8//pCDg0OOfyMfHx+5u7vrjz/+MGvPz3sXAAAUHPe9OXHfe2e3/5uVK1dOPj4+ZvdxPXr00OLFi7Vlyxb16NFDx48f16+//qrJkyffceybubnTpIe7uXDhgubPn69NmzYpOTnZbN+ta9OOGjVKY8eO1cMPP6z7779fbdu2VY8ePUyF5erVq2vQoEGKjo7Wxo0b1aJFC7Vr107du3dnmQSgkFG4BWAV2dnZMhgMWrx4ca5PtS1btqykG+tWDRo0SBcvXtTzzz+v++67T2XLltW5c+c0duxYqz4EITf5eeJudna2Wrdureeffz7X/bVq1fpHMRiNRknSzJkz5ePjc9cYi/opwXkd72bcBZWRkaGTJ0/ecT1Wg8GgefPmad++ffr++++1bds2hYeHKzo6Wp988km+Zhy4uLjIwaFovlBy+4MyCuLm2mJ3w9OiAQCwD9z35l9Jve+9Vd26dXX//ffr888/V48ePfT555/L2dlZnTp1uuPr7rvvPknK8dBcS7z66qvau3evwsLC1KBBA5UtW1bZ2dl6/vnnzc6xc+fOatGihb799lv99NNPWrJkiRYvXqx3331Xbdu2lXTjYW+hoaHaunWrfvrpJ02dOlWLFi3SmjVr/tFazADujMItAKuoUaOGjEajfH19Vbt27Tz7/fbbbzp58qRmzJihHj16mNp/+ukns35Vq1aVdGMWwO1OnDhhnaDzUKNGDV25ckXBwcGFMv7Nv1x7eXlZ7RhVq1bVzp07dfXqVbPZB6dPn87RN7+FQmv7+uuvde3aNYWEhNy1b9OmTdW0aVO99tpr2rhxo0aNGqVNmzbpySeftHr8ub3HTp48qWrVqpm2PTw8cv3K3M0ZMjdZElu1atWUnZ2tU6dOqU6dOqb2pKQkpaammh0fAADYD+5786+43/eeOnVKDz74oGk7LS1NiYmJeuihh8z69ejRQ1FRUTp//ry++OILPfzww2ZLNOSmdu3aql27trZu3aq0tDSLl0y4ePGiYmNjNWzYMA0dOtTUfnMW9O0qVqyovn37qm/fvkpOTlZoaKgWLlxoKtxKNx666+/vr5dfflm//PKL+vTpo1WrVuX54GEA/xxr3AKwio4dO8rR0VHz58/P8Rdqo9Fo+nrZzZmQt/YxGo1avny52WsqVqyoBg0aaP369WZf4/npp5909OjRwjoNSVKnTp20d+9ebdu2Lce+1NRUZWZm/qPx27RpI1dXVy1atCjXdVwL8pW0kJAQZWRkaM2aNaa27OxsrVy5Mkffmze41lj6IL8OHz6s6dOny8PD447rj128eDHH+6dBgwaSpPT0dEnWj3/Lli1m63nFxcVp//79Zjfc1atX1/Hjx83+bQ4fPqxffvnFbCxLYrt5E7xs2TKz9ujoaLP9AADAvnDfm3/F/b73k08+MTuvVatWKTMzM0fhtmvXrjIYDJo2bZrOnDmj7t2752v84cOH68KFC5owYUKu/xbbt2/X999/n+tr85pNfPu9Z1ZWltn7TrpRaK9YsaLp/vvy5cs5ju/n5ycHBwdTHwCFgxm3AKyiRo0aevXVVzV79mz98ccfat++vcqVK6ezZ89qy5YteuqppxQWFqb77rtPNWrU0IwZM3Tu3Dm5urrq66+/zvVm6vXXX9eQIUP0zDPPqFevXrpw4YI++ugj1atXT1euXCm0cwkLC9N3332nF198UaGhobr//vt19epV/fbbb/r666+1devWHGtv3S4lJUX//ve/c7T7+vqqe/fuioiI0OjRo9WzZ0917txZnp6eSkhI0I8//qhmzZpp4sSJFsXcvn17BQQEaMaMGTp9+rTuu+8+s7XUbp1tcP/990uSpk6dqpCQEDk6OqpLly4WHe9Ofv75Z12/fl3Z2dm6cOGCfvnlF3333XdydXXV/Pnzc/2a3E3r16/XqlWr1L59e9WoUUNpaWlas2aNXF1dTTfApUuXVt26dbV582bVqlVL5cuXV7169eTn51egeGvUqKE+ffqoT58+Sk9P1/Lly1W+fHmzrww+8cQTWrp0qcLCwvTEE08oOTlZq1evVt26dc3WHbMktvr16ys0NFSffPKJUlNT1bJlSx04cEDr169X+/btzWZvAAAA+8F9r7mSfN+bkZGhgQMHqlOnTjpx4oQ+/vhjNW/eXI8++qhZP09PT7Vp00ZfffWV3N3d9fDDD+dr/M6dO+vIkSNauHChDh48qK5du6pq1aq6cOGCtm3bptjYWM2ePTvX17q6uqply5b64IMPlJGRoUqVKumnn34ye9CbdGOWcNu2bfXYY4+pfv36Klu2rGJiYnTgwAGNHTtWkrRjxw699dZb+te//qVatWopKytLn332mRwdHfXYY49ZnjgA+UbhFoDVDB48WLVq1dLSpUu1YMECSVLlypXVunVrtWvXTpLk7OyshQsXmtZEKlWqlDp06KC+ffvq8ccfNxvvoYce0ty5czVnzhzNnj1bNWrUUGRkpLZu3apdu3YV2nmUKVNGK1as0KJFi/TVV19pw4YNcnV1Va1atTRs2LB8LcCfnJysuXPn5mhv1aqVunfvrm7duqlixYp6//33tWTJEqWnp6tSpUpq0aKFevbsaXHMjo6OWrRokaZNm6b169fLwcFBHTp00CuvvKI+ffqoVKlSpr4dO3bUs88+qy+//FKff/65jEajVW9gV6xYIenGv7Wbm5vq1KmjYcOG6amnnrrrjf8DDzygAwcOaNOmTUpKSpKbm5sCAgI0a9Yss6fuTp06VVOmTFFkZKQyMjI0dOjQAhdue/ToIQcHBy1btkzJyckKCAjQm2++qYoVK5r61KlTRzNmzNC8efMUGRmpunXraubMmfriiy9yvBctiW3q1Kny9fXV+vXrtWXLFnl7e2vIkCFmX2cDAAD2h/ve/ynJ970TJ07Uxo0bNW/ePGVkZKhLly6aMGFCrks0PP744/r+++/VqVOnfD90V5Jee+01Pfjgg1qxYoVWrVqlixcvyt3dXU2aNNG///3vHEXiW82ePVtTpkzRxx9/LKPRqNatW2vx4sVq06aNqU/p0qXVp08f/fTTT/rmm29kNBpVo0YNTZo0Sc8884ykG0skhISE6Pvvv9e5c+dUpkwZ+fv7a/HixWratGn+EwbAYgajNVfdBgDYlS1btuiVV14x/fUfAAAAKI7s/b73ZnwrV65UixYtbB0OgHsEa9wCQDFx7do1s+2srCytWLFCrq6upq+JAQAAAPe6e/G+9z//+Y+qV69ul0VlAPaLpRIAoJiYMmWKrl27psDAQKWnp+ubb77R3r179frrr6t06dK2Dg8AAACwinvpvvfLL7/UkSNH9MMPP2j8+PG5LqMAAHlhqQQAKCY2btyo6OhonTp1StevX1fNmjXVp08f9evXz9ahAQAAAFZzL933+vv7q2zZsurcubMmT54sJyfmzwHIPwq3AAAAAAAAAGBnWOMWAAAAAAAAAOwMhVsAAAAAAAAAsDMsrpKHxMRLVh3P07OcUlLSrDpmcUa+LEO+LEO+LEO+LEO+LEO+LEO+cufj42brEOyCte9fgbxwLQJQHHFtQ1HK7/0rM26LgMEgOTo6iIdH5g/5sgz5sgz5sgz5sgz5sgz5sgz5AmAPuBYBKI64tsFeUbgFAAAAAAAAADtD4RYAAAAAAAAA7IxNC7ft2rWTv79/jp/JkydLkq5fv67JkycrKChIgYGBGjZsmJKSkszGSEhI0ODBg9WkSRO1atVKM2bMUGZmplmfnTt3KjQ0VI0aNVKHDh20bt26IjtHAAAAAAAAALCUTR9O9umnnyorK8u0/fvvv2vQoEH617/+JUmaPn26fvzxR82ZM0dubm6aMmWKhg4dqtWrV0uSsrKyNGTIEHl7e2v16tU6f/68xowZI2dnZ73++uuSpDNnzmjIkCF6+umnNWvWLMXGxmrChAny8fFRmzZtiv6kAQAAAAAAAOAubFq49fT0NNt+//33VaNGDT3wwAO6dOmS1q5dq1mzZqlVq1aSbhRyO3furH379qlp06bavn27jh49qujoaHl7e6tBgwYaMWKEZs2apaFDh8rFxUWrV6+Wr6+vxo4dK0mqU6eO9uzZo6VLl961cGutRalvjsMi1/lDvixDvixDvixDvixDvixDvixDvgAAAICSxaaF21ulp6fr888/16BBg2QwGBQfH6+MjAwFBweb+tSpU0dVq1Y1FW737dsnPz8/eXt7m/qEhIQoIiJCR48eVcOGDbVv3z5T4ffWPtOnT79jPJ6e5eToaN2VJLy83Kw6XnFHvixDvixDvixDvixDvixDvixDvgAAAICSwW4Kt1u2bNGlS5cUGhoqSUpKSpKzs7Pc3d3N+nl5eSkxMdHU59airSTT9t36XL58WdeuXVPp0qVzjSclJc2qM269vNyUnHxJRqN1xizOyJdlyJdlyJdlyJdlyJdlyJdlyFfevL0pZgMAAKD4sZvC7dq1a/XQQw+pUqVKtg7FxNofioxG649ZnJEvy5Avy5Avy5Avy5Avy5Avy5AvAAAAoGSw7loABfTHH38oJiZGTzzxhKnN29tbGRkZSk1NNeubnJwsHx8fU5+kpCSz/Te379bH1dU1z9m2AAAAAAAAAGBLdlG4Xbdunby8vPTwww+b2ho1aiRnZ2fFxsaa2o4fP66EhAQ1bdpUktS0aVP99ttvSk5ONvWJiYmRq6ur6tata+qzY8cOs+PFxMSYxgAAAAAAAAAAe2Pzwm12drbWrVunHj16yMnpfys3uLm5qVevXoqKitKOHTsUHx+v8PBwBQYGmoquISEhqlu3rkaPHq3Dhw9r27ZtmjNnjvr27SsXFxdJ0tNPP60zZ85o5syZOnbsmFauXKnNmzdr4MCBNjhbAAAAAAAAALg7m69xGxMTo4SEBPXq1SvHvvDwcDk4OGj48OFKT09XSEiIJk2aZNrv6OiohQsXKiIiQr1791aZMmUUGhqq4cOHm/pUr15dixYtUmRkpJYvX67KlStr6tSpatOmTZGcHwAAAAAAAOxTVlaWdu6M0ZUrF1W2rIeCgoLl6Oho67AASZLBaOTxFrlJTLxktbEMhhtPO05K4inQ+UG+LEO+LEO+LEO+LEO+LFOc81XmP5sKZVwXFyelp2fmaL/6ZOdCOd4/MW1ahC5fvqTIyNmFfiwfH7dCP8a9wJr3r0BeivO1G0DJ88UXnysiYrxOnz5laqtRo6YiIqapa9fuNowMxV1+719tvlQCAAAAita0aREKCWmhkJAWats2SE8+2V3//vdcXb9+3dahAQAAFIkvvvhcYWHPqkGDhtq8eYsuXbqkzZu3qEGDhgoLe1ZffPG5rUMEbL9UAgAAAIpeUFCwwsMnKjMzU0eOHNa0aZMkGfTyy8Pv+loAAIB7WVZWliIixqtjx39p2bJVcnR0kKurq1q0eEDLlq3SgAF9FBExQZ06dWHZBNgUhVsAAIASyMXFWV5e3pKkSpUq6+uvH9DPP++UdOPhsStXLtPnn69XcnKyqlevoYEDw/TII+0l3fiwM3PmNP3yy89KTk5WpUqVFBr6pJ56qo/NzgcAACC/duyI0enTp7Rw4RI5OJh/Gf3Gs5ZeV5cuHbRjR4xat+YZSbAdCrcAAAAl3PHjRxUfH6dKlapIklasiNY332zWqFHj5OtbXfv379WUKRNVvnwFBQY2l9FoVMWKlTRlSpTc3T0UHx+nmTOnycvLW48+2sHGZwMAAHBn5879JUmqX79hrvsbNGho1g+wFQq3xdCJmHFWG6t2cKTVxgIAAPYjJma7OnRoo6ysLKWnp8vBwUGvvTZa6enpWrEiWnPm/FuNGgVIkqpV81Vc3D599tk6BQY2l5OTk8LChpjGqlq1muLj4/T9999SuAUAAHavUqXKkqTDhw+qRYsHcuw/dOigWT/AVijcAgAAlECBgc01atQ4Xb16VWvWfCxHR0c9/PCjOn78mK5du6bXXnvFrH9GRobq1fM3ba9du0Zffvm5zp//S9evX/+//X5FfRoAAAAWe/DBYNWoUVNz5842rXF7U3Z2tubNe0c1atTSgw8G2zBKgMItAABAiVSmTBn5+laXJI0bN1EDB/bRF19sUO3adSVJM2fOkY9PRbPXODs7S5K2bPlaCxbM1dChr6pRo8YqW7acPv54uQ4e/LVoTwIAAKAAHB0dFRExTWFhz2rAgD4aMeJ1hYQEaffunZo79x19881XWrJkBQ8mg81RuAUAACjhHBwc9OyzgzR//v/TqlXr5OLionPn/lJgYPNc+x84sF+NGweoZ88nTW1//PFHUYULAADwj3Xt2l1LlqxQRMR4de78v6WeatSopSVLVqhr1+42jA64gcItAAAA9Mgj7fXvf8/Thg3r9PTT/fTuu+/IaDQqIKCpLl++rAMH9qlcOVd16tRVvr419NVXX2rnzlhVqVJVX3+9SYcP/6oqVarZ+jQAAADyrWvX7urUqYt27ozRlSsXVbash4KCgplpC7tB4RYAAMDKrj7Z2epjGgySq7ebUpMuyWi0+vBycnJSz55P6eOPl+s///lc5ctX0IoV0UpI+EOurm7y86uv/v0HSZIef7ynfv/9iCZNGifJoPbtH1No6JPasSPG+oEBAAAUIkdHR7Vu3Ube3m5KKqT7LKCgDEYjb8ncJCZestpYBoOK9AJwImac1caqHRxptbHyq6jzda8jX5YhX5YhX5YhX5YhX5YhX3nz8XGzdQh2wZr3r0BeuBYBKI64tqGo5ff+1eHuXQAAAAAAAAAARYnCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAAAAAgJ2hcAsAAAAAAAAAdobCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAAAAAgJ2hcAsAAAAAAAAAdsbJ1gEAAAAUNydixhXKuGddnJSenpmjvXZwZKEcryCeeKKbnnqqj5566hlbhwIAAADc0yjcAgAAlEB///23lixZqJiY7fr77xS5ubmrbt16GjjweQUENL3r6zdt2qh582brq69+MGtfvHi5ypQpUzhBAwAAACUIhVsAAIASaMKE0crIyNCECZNVtWo1paQka8+e3UpNvfiPxq1QocId92dmZsrJiVtQAAAA4G64awYAAChhLl26pP379+rddxcpMLC5JKly5Spq2LCRqc/q1R9p06aNSkj4Q+7uHgoObqOXXx6usmXL6pdfftb06ZMlSSEhLSRJgwa9oLCwITmWSggJaaGRI8dqx46ftGfPbvXp86zCwoZo27YfFB29WCdPnpCXl486deqi/v2fo6gLAAAA/B/ujAEAAEqYMmXKqEyZstq27Qfdf39jubi45Ojj4OCgV199Q1WqVFVCwh+aPTtK//73PI0aNVaNGzfR8OEjtWTJQn388dr/G7Nsnsf78MP39eKLQzV8+Eg5Ojpp//69mjp1kl599Q0FBDRVQsJZzZw5XZL03HODC+OUAQAAgHuOg60DAAAAQNFycnLS+PGTtHnzl/rXvx7RSy89p0WLFujo0d9NfZ566hk1a9ZCVapUVfPmLfXCCy/p+++/lSQ5OzvL1dVVBoNBXl7e8vLyVtmyeRduO3R4TF26dFe1ar6qXLmyPvxwsfr1G6hOnbqqWjVftWz5oJ5//kV99tm6Qj93AAAA4F7BjFsAAIAS6OGHH1WrViGKi9urX3+N144dMfr44+UaM2aCOnfupt27d+qjj5bq1KmTSktLU1ZWltLTr+vatWsqXbq0RceqX7+h2faxY7/pwIH9Wr78Q1NbVlZ2gce3N7t379aSJUsUHx+vxMRELViwQO3bt8+178SJE/XJJ59o3LhxGjhwoKn9woULmjJlir7//ns5ODioY8eOGj9+vMqVK1dEZwEAAABbo3ALAABQQpUqVUotWz6oli0f1MCBzysqaoqWLLmx7u2YMa+pR49eeuGFl+Xu7q64uH2KipqijIwMiwurpUuXMdu+cuWqwsIGq23bdjn65rZsw73mypUr8vf3V69evTR06NA8+3377bfav3+/KlasmGPfqFGjlJiYqOjoaGVkZCg8PFwTJ07U7NmzCzN0AAAA2BEKtwAAAJAk1apVW9u2/aAjRw4pOztbQ4e+JgeHGytrfffdt2Z9nZyclZWVXaDj+Pv76/TpU/L1rf4PI7ZPbdu2Vdu2be/Y59y5c5oyZYqWLFmiIUOGmO07duyYtm3bpk8//VSNGzeWJE2YMEGDBw/W6NGjValSpUKLHQAAAPaDwi0AAEAJc/HiBb355lh16dJdderUU9myZXX48CF9/PEKhYS0VbVq1ZWZmalPP/1ErVu30YED+3OsP1ulShVdvXpFP/+8S3Xr+ql06dL5nok7cOALGj36VVWqVFkPP/yoHBwcdPTobzp+/JgGD365ME7ZrmRnZ+uNN95QWFiY6tWrl2P/3r175e7ubiraSlJwcLAcHBwUFxenDh065Dm2wVAoIQMmN99jvNcAFCdc22CvKNwCAABYWe3gSKuPaTBI3t5uSkq6JKPxn41VpkxZNWzYSJ988rESEs4qMzNTFStWUrduPdS//yCVKlVaw4a9ppUrl2nRovlq0qSZhgx5RVOnTjKN0bhxE/Xo0UuTJo3TxYsXNWjQCwoLG3KHo/5PUFArzZw5R0uXLtbKlcvk5OSkGjVqqVu3Hv/sxO4RixcvlpOTk/r375/r/qSkJHl6epq1OTk5ycPDQ4mJiXmO6+lZTo6OPHsYRcPLy83WIQCA1XFtg72hcAsAAFDCuLi46MUXh+rFF/Nef7V3777q3buvWdu//tXFbHvUqHEaNWqcWdunn240296+/edcxw8KaqWgoFaWhF0sxMfHa/ny5Vq3bp0MVp7Wk5KSxkwhFDqD4UZhIzn5n/8RCQDsBdc2FDVv7/z9kYDCLQAAAFBEfv75ZyUnJ+uRRx4xtWVlZWnGjBlavny5vvvuO3l7eyslJcXsdZmZmbp48aJ8fHzuOD4fNlFUjEbebwCKH65tsDcUbgEAAIAi8vjjjys4ONisLSwsTI8//rh69uwpSQoMDFRqaqri4+PVqFEjSdKOHTuUnZ2tgICAIo8ZAAAAtkHhFgAAALCitLQ0nT592rR99uxZHTp0SB4eHqpataoqVKhg1t/Z2Vne3t667777JEl16tRRmzZt9Oabb2ry5MnKyMjQlClT1KVLF1WqVKlIzwUAAAC2Q+EWAAAAsKL4+HizB49FRt54WF1oaKiioqLyNcasWbM0ZcoUDRgwQA4ODurYsaMmTJhQKPECAADAPlG4BQAAAKwoKChIR44cyXf/7777Lkdb+fLlNXv2bGuGBQAAgHuMg60DAAAAAAAAAACYo3ALAAAAAAAAAHaGwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BmbF27PnTunUaNGKSgoSAEBAerWrZsOHDhg2m80GjV37lyFhIQoICBAAwcO1MmTJ83GuHDhgkaOHKlmzZqpRYsWCg8PV1pamlmfw4cP65lnnlHjxo3Vtm1bLV68uChODwAAAAAAAAAsZtPC7cWLF9WnTx85Oztr8eLF+vLLLzVmzBh5eHiY+ixevFgrVqxQRESE1qxZozJlyigsLEzXr1839Rk1apSOHj2q6OhoLVy4UD///LMmTpxo2n/58mWFhYWpatWqWrdunUaPHq358+frk08+KdLzBQAAAAAAAID8cLLlwRcvXqzKlSsrMjLS1Fa9enXT70ajUcuXL9dLL72k9u3bS5Jmzpyp4OBgbdmyRV26dNGxY8e0bds2ffrpp2rcuLEkacKECRo8eLBGjx6tSpUq6fPPP1dGRoamT58uFxcX1atXT4cOHVJ0dLR69+5dtCcNAAAAAAAAAHdh08Ltd999p5CQEA0fPly7d+9WpUqV9Mwzz+ipp56SJJ09e1aJiYkKDg42vcbNzU1NmjTR3r171aVLF+3du1fu7u6moq0kBQcHy8HBQXFxcerQoYP27dunFi1ayMXFxdQnJCREixcv1sWLF81m+N7KYLDOed4cx1rjFSVbxHwv58sWyJdlyJdlyJdlyJdlyJdlyBcAAABQsti0cHvmzBmtWrVKgwYN0osvvqgDBw5o6tSpcnZ2VmhoqBITEyVJXl5eZq/z8vJSUlKSJCkpKUmenp5m+52cnOTh4WF6fVJSknx9fc36eHt7m/blVrj19CwnR0frriTh5eVm1fHyctbFev+s3t5FE3NuiipfxQX5sgz5sgz5sgz5sgz5sgz5AgAAAEoGmxZujUajGjVqpNdff12S1LBhQ/3+++9avXq1QkNDbRmaUlLSrDrj1svLTcnJl2Q0WmfMO0lPz7TaWElJl6w2Vn4Vdb7udeTLMuTLMuTLMuTLMuTLMuQrb7b8QzMAAABQWGxauPXx8VGdOnXM2u677z59/fXXpv2SlJycrIoVK5r6JCcnq379+pJuzJxNSUkxGyMzM1MXL140vd7b29s0Q/emm9s3Z97mxtofioxG649Z2GwZ772YL1siX5YhX5YhX5YhX5YhX5YhXwAAAEDJYN21ACzUrFkznThxwqzt5MmTqlatmiTJ19dXPj4+io2NNe2/fPmy9u/fr8DAQElSYGCgUlNTFR8fb+qzY8cOZWdnKyAgQJLUtGlT/fzzz8rIyDD1iYmJUe3atfNc3xYAAAAAAAAAbMWmhdsBAwZo//79WrhwoU6dOqWNGzdqzZo1euaZZyRJBoNB/fv313vvvaetW7fqyJEjGj16tCpWrKj27dtLkurUqaM2bdrozTffVFxcnPbs2aMpU6aoS5cuqlSpkiSpW7ducnZ21vjx4/X7779r06ZNWr58uQYNGmSzcwcAAAAAAACAvNh0qYSAgADNnz9f77zzjhYsWCBfX1+Fh4ere/fupj4vvPCCrl69qokTJyo1NVXNmzfXBx98oFKlSpn6zJo1S1OmTNGAAQPk4OCgjh07asKECab9bm5uWrJkid566y317NlTFSpU0Msvv6zevXsX6fkCAAAAAAAAQH4YjEZWSctNYqL1HsplMNx4aEZSUtE8TOREzDirjVU7ONJqY+VXUefrXke+LEO+LEO+LEO+LEO+LEO+8ubjw8PJJOvevwJ54VoEoDji2oailt/7V5sulQAAAAAAAAAAyInCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAAAAAgJ2hcAsAAAAAAAAAdobCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAAAAAgJ2hcAsAAAAAAAAAdobCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAAAAAgJ2hcAsAAAAAAAAAdobCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAAAAAgJ2hcAsAAAAAAAAAdobCLQAAAAAAAADYGQq3AAAAAAAAAGBnKNwCAAAAVrR79269+OKLCgkJkb+/v7Zs2WLal5GRobffflvdunVT06ZNFRISotGjR+vcuXNmY1y4cEEjR45Us2bN1KJFC4WHhystLa2oTwUAAAA2ROEWAAAAsKIrV67I399fkyZNyrHv2rVrOnjwoF566SWtW7dO8+fP14kTJ/TSSy+Z9Rs1apSOHj2q6OhoLVy4UD///LMmTpxYVKcAAAAAO+Bk6wAAAACA4qRt27Zq27Ztrvvc3NwUHR1t1vbmm2/qySefVEJCgqpWrapjx45p27Zt+vTTT9W4cWNJ0oQJEzR48GCNHj1alSpVKvRzAAAAgO1RuAUAAABs6PLlyzIYDHJ3d5ck7d27V+7u7qairSQFBwfLwcFBcXFx6tChQ55jGQyFHi5KuJvvMd5rAIoTrm2wVxRuAQAAABu5fv26Zs2apS5dusjV1VWSlJSUJE9PT7N+Tk5O8vDwUGJiYp5jeXqWk6MjK6GhaHh5udk6BACwOq5tsDcUbgEAAAAbyMjI0IgRI2Q0GjV58uR/PF5KShozhVDoDIYbhY3k5EsyGm0dDQBYB9c2FDVv7/z9kYDCLQAAAFDEMjIy9OqrryohIUHLli0zzbaVJG9vb6WkpJj1z8zM1MWLF+Xj43PHcfmwiaJiNPJ+A1D8cG2DveG7VAAAAEARulm0PXXqlJYuXaoKFSqY7Q8MDFRqaqri4+NNbTt27FB2drYCAgKKOlwAAADYCDNuAQAAACtKS0vT6dOnTdtnz57VoUOH5OHhIR8fHw0fPlwHDx7UokWLlJWVZVq31sPDQy4uLqpTp47atGmjN998U5MnT1ZGRoamTJmiLl26qFKlSrY6LQAAABQxCrcAAACAFcXHx6t///6m7cjISElSaGiohg4dqu+++06S9Pjjj5u9bvny5QoKCpIkzZo1S1OmTNGAAQPk4OCgjh07asKECUV0BgAAALAHFG4BAAAAKwoKCtKRI0fy3H+nfTeVL19es2fPtmZYAAAAuMewxi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdsWnh9t1335W/v7/Zz7/+9S/T/uvXr2vy5MkKCgpSYGCghg0bpqSkJLMxEhISNHjwYDVp0kStWrXSjBkzlJmZadZn586dCg0NVaNGjdShQwetW7euSM4PAAAAAAAAAArCydYB1KtXT9HR0aZtR0dH0+/Tp0/Xjz/+qDlz5sjNzU1TpkzR0KFDtXr1aklSVlaWhgwZIm9vb61evVrnz5/XmDFj5OzsrNdff12SdObMGQ0ZMkRPP/20Zs2apdjYWE2YMEE+Pj5q06ZN0Z4sAAAAAAAAAOSDzQu3jo6O8vHxydF+6dIlrV27VrNmzVKrVq0k3Sjkdu7cWfv27VPTpk21fft2HT16VNHR0fL29laDBg00YsQIzZo1S0OHDpWLi4tWr14tX19fjR07VpJUp04d7dmzR0uXLr1r4dZgsM453hzHWuMVJVvEfC/nyxbIl2XIl2XIl2XIl2XIl2XIFwAAAFCy2Lxwe+rUKYWEhKhUqVJq2rSpRo4cqapVqyo+Pl4ZGRkKDg429a1Tp46qVq1qKtzu27dPfn5+8vb2NvUJCQlRRESEjh49qoYNG2rfvn2mwu+tfaZPn37HuDw9y8nR0borSXh5uVl1vLycdbHeP6u3d9HEnJuiyldxQb4sQ74sQ74sQ74sQ74sQ74AAACAksGmhduAgABFRkaqdu3aSkxM1IIFC9S3b19t3LhRSUlJcnZ2lru7u9lrvLy8lJiYKElKSkoyK9pKMm3frc/ly5d17do1lS5dOtfYUlLSrDrj1svLTcnJl2Q0WmfMO0lPz7x7p3xKSrpktbHyq6jzda8jX5YhX5YhX5YhX5YhX5YhX3mz5R+aAQAAgMJi08Jt27ZtTb/Xr19fTZo00SOPPKLNmzfnWVAtStb+UGQ0Wn/MwmbLeO/FfNkS+bIM+bIM+bIM+bIM+bIM+QIAAABKBuuuBfAPubu7q1atWjp9+rS8vb2VkZGh1NRUsz7JycmmNXG9vb2VlJRktv/m9t36uLq62kVxGAAAAAAAAABuZ1eF27S0NJ05c0Y+Pj5q1KiRnJ2dFRsba9p//PhxJSQkqGnTppKkpk2b6rffflNycrKpT0xMjFxdXVW3bl1Tnx07dpgdJyYmxjQGAAAAAAAAANgbmxZuZ8yYoV27duns2bP65ZdfNHToUDk4OKhr165yc3NTr169FBUVpR07dig+Pl7h4eEKDAw0FV1DQkJUt25djR49WocPH9a2bds0Z84c9e3bVy4uLpKkp59+WmfOnNHMmTN17NgxrVy5Ups3b9bAgQNtd+IAAAAAAAAAcAc2XeP2r7/+0uuvv64LFy7I09NTzZs315o1a+Tp6SlJCg8Pl4ODg4YPH6709HSFhIRo0qRJptc7Ojpq4cKFioiIUO/evVWmTBmFhoZq+PDhpj7Vq1fXokWLFBkZqeXLl6ty5cqaOnWq2rRpU+TnCwAAAAAAAAD5YTAaebxFbhITL1ltLIPhxtOOk5KK5inQJ2LGWW2s2sGRVhsrv4o6X/c68mUZ8mUZ8mUZ8mUZ8mUZ8pU3Hx83W4dgF6x5/wrkhWsRgOKIaxuKWn7vX+1qjVsAAAAAAAAAAIVbAAAAAAAAALA7FG4BAAAAAAAAwM5QuAUAAAAAAAAAO0PhFgAAAAAAAADsDIVbAAAAAAAAALAzFG4BAAAAAAAAwM5QuAUAAAAAAAAAO0PhFgAAAAAAAADsDIVbAAAAAAAAALAzFG4BAAAAAAAAwM5QuAUAAACsaPfu3XrxxRcVEhIif39/bdmyxWy/0WjU3LlzFRISooCAAA0cOFAnT54063PhwgWNHDlSzZo1U4sWLRQeHq60tLQiPAsAAADYGoVbAAAAwIquXLkif39/TZo0Kdf9ixcv1ooVKxQREaE1a9aoTJkyCgsL0/Xr1019Ro0apaNHjyo6OloLFy7Uzz//rIkTJxbVKQAAAMAOULgFAAAArKht27Z67bXX1KFDhxz7jEajli9frpdeeknt27dX/fr1NXPmTJ0/f940M/fYsWPatm2bpk6dqiZNmqhFixaaMGGCvvzyS507d66oTwcAAAA24mTrAAAAAABb+/XXX+Xk5CR/f39J0pYtW7Ru3TrVrVtXQ4cOlYuLi1WOc/bsWSUmJio4ONjU5ubmpiZNmmjv3r3q0qWL9u7dK3d3dzVu3NjUJzg4WA4ODoqLi8u1IHyTwWCVMIE83XyP8V4DUJxwbYO9onALAACAEm/ixIkaPHiw/P39debMGb3++uvq0KGDvvrqK129elXjx4+3ynESExMlSV5eXmbtXl5eSkpKkiQlJSXJ09PTbL+Tk5M8PDxMr8+Np2c5OTryhToUDS8vN1uHAABWx7UN9obCLQAAAEq8kydPqkGDBpKkzZs3q2XLlpo9e7b27Nmj119/3WqF28KUkpLGTCEUOoPhRmEjOfmSjEZbRwMA1sG1DUXN2zt/fySgcAsAAIASz2g0Kjs7W5IUGxurhx9+WJJUpUoV/f3331Y7jo+PjyQpOTlZFStWNLUnJyerfv36kiRvb2+lpKSYvS4zM1MXL140vT4vfNhEUTEaeb8BKH64tsHe8F0qAAAAlHiNGjXSe++9pw0bNmj37t2mwu3Zs2fl7e1tteP4+vrKx8dHsbGxprbLly9r//79CgwMlCQFBgYqNTVV8fHxpj47duxQdna2AgICrBYLAAAA7BszbgEAAFDihYeH64033tCWLVv04osvqmbNmpKkr7/+2lRQza+0tDSdPn3atH327FkdOnRIHh4eqlq1qvr376/33ntPNWvWlK+vr+bOnauKFSuqffv2kqQ6deqoTZs2evPNNzV58mRlZGRoypQp6tKliypVqmS9kwYAAIBdo3ALAACAEq9+/frauHFjjvbRo0fLwcGyL6nFx8erf//+pu3IyEhJUmhoqKKiovTCCy/o6tWrmjhxolJTU9W8eXN98MEHKlWqlOk1s2bN0pQpUzRgwAA5ODioY8eOmjBhQgHPDgAAAPciCrcAAABAHm4tpuZXUFCQjhw5kud+g8GgESNGaMSIEXn2KV++vGbPnm3xsQEAAFB8ULgFAABAidSyZUsZDIZ89d21a1chRwMAAACYo3ALAACAEik8PNz0+4ULF/Tee+8pJCRETZs2lSTt27dP27dv18svv2yjCAEAAFCSUbgFAABAiRQaGmr6fdiwYRo+fLj69etnauvfv78++ugjxcTEaODAgTaIEAAAACWZZU9aAAAAAIqh7du3q02bNjna27Rpo9jYWBtEBAAAgJKOwi0AAABKvPLly2vr1q052rdu3ary5csXfUAAAAAo8VgqAQAAACXesGHDNGHCBO3atUsBAQGSpLi4OG3btk1TpkyxcXQAAAAoiSjcAgAAoMTr2bOn6tSpo+XLl+vbb7+VJN133336+OOP1aRJExtHBwAAgJKIwi0AAABKtIyMDE2cOFEvv/yyZs+ebetwAAAAAEmscQsAAIASztnZWd98842twwAAAADMULgFAABAide+fftcH04GAAAA2ApLJQAAAKDEq1mzphYsWKBffvlF999/v8qUKWO2v3///jaKDAAAACUVhVsAAACUeJ9++qnc3NwUHx+v+Ph4s30Gg4HCLQAAAIochVsAAACUeN99952tQwAAAADMsMYtAAAAcAuj0Sij0WjrMAAAAFDCUbgFAAAAJG3YsEHdunVTQECAAgIC1K1bN23YsMHWYQEAAKCEYqkEAAAAlHjR0dGaO3eu+vbtq1dffVWStGfPHkVEROjChQsaOHCgTeMDAABAyUPhFgAAACXeihUrFBERoR49epjaHn30UdWrV0/vvvsuhVsAAAAUuQItlXDmzBlrxwEAAADYTGJiogIDA3O0BwYGKjEx0QYRAQAAoKQrUOG2Q4cOevbZZ/XZZ5/p+vXr1o4JAAAAKFI1a9bU5s2bc7Rv2rRJtWrVKvqAAAAAUOIVaKmE9evXa+3atYqKitKUKVPUuXNnPfHEEwoICLB2fAAAAEChGzZsmF577TXt3r1bzZo1kyT98ssv2rFjh+bMmWPb4AAAAFAiFWjGbYMGDTRhwgRt27ZN06dP1/nz5/XMM8+oa9euio6OVkpKirXjBAAAAArNY489pjVr1qhChQraunWrtm7dqgoVKug///mPOnToYOvwAAAAUAL9o4eTOTk5qWPHjnr44Yf18ccfa/bs2ZoxY4beeecdderUSaNGjVLFihWtFSsAAABQaBo1aqRZs2bZOgwAAABA0j8s3B44cEBr167Vpk2bVKZMGT333HN64okndO7cOc2fP18vv/yyPv3003yN9f7772v27Nnq37+/xo8fL0m6fv26oqKitGnTJqWnpyskJESTJk2St7e36XUJCQmKiIjQzp07VbZsWfXo0UMjR46Uk9P/Tm3nzp2KiorS77//ripVquill15Sz549/8mplxgnYsZZZZzawZFWGQcAAKAwjB49WkFBQXrggQdUvXp1W4cDAAAAFKxwGx0drXXr1unEiRN66KGHNGPGDLVt21YODjdWXqhevbqioqLUrl27fI0XFxen1atXy9/f36x9+vTp+vHHHzVnzhy5ublpypQpGjp0qFavXi1JysrK0pAhQ+Tt7a3Vq1fr/PnzGjNmjJydnfX6669Lks6cOaMhQ4bo6aef1qxZsxQbG6sJEybIx8dHbdq0KcjpAwAAoJhxdnbW+++/r/Hjx6tSpUpq2bKlgoKC1LJlSx5OBgAAAJsoUOF21apV6tWrl0JDQ/NcCsHT01PTpk2761hpaWl64403NHXqVL333num9kuXLmnt2rWaNWuWWrVqJelGIbdz587at2+fmjZtqu3bt+vo0aOKjo6Wt7e3GjRooBEjRmjWrFkaOnSoXFxctHr1avn6+mrs2LGSpDp16mjPnj1aunTpXQu3BkN+M3JnN8ex1nj3IkvOnXxZhnxZhnxZhnxZhnxZhnxZhnwVrpv3refOndPu3bu1a9cuffjhh5o4caJ8fHz03//+18YRAgAAoKQpUOH2m2++uWsfFxcXhYaG3rXfW2+9pbZt2yo4ONiscBsfH6+MjAwFBweb2urUqaOqVauaCrf79u2Tn5+f2dIJISEhioiI0NGjR9WwYUPt27fPVPi9tc/06dPvGJenZzk5Ohbo2W158vJys+p4eTnr8o9WwCgU3t6Wn3tR5au4IF+WIV+WIV+WIV+WIV+WIV+Fy93dXeXLl5eHh4fc3d3l6OgoT09PW4cFAACAEqhAFb61a9eqbNmy6tSpk1n75s2bde3atXwVbCXpyy+/1MGDB3NdBzcpKUnOzs5yd3c3a/fy8lJiYqKpz61FW0mm7bv1uXz5sq5du6bSpUvnGltKSppVZ9x6ebkpOfmSjEbrjHkn6emZhX8QCyUlXcp336LO172OfFmGfFmGfFmGfFmGfFmGfOWtIH8gvt0777yjXbt26eDBg6pTp45atmypF154QS1btpSHh4cVogQAAAAsU6DC7fvvv6/JkyfnaPfy8tKbb76Zr8Ltn3/+qWnTpunDDz9UqVKlChJGobP2hyKj0fpj3isKct4lOV8FQb4sQ74sQ74sQ74sQ74sQ74Kx/vvvy9PT08NHTpUHTp0UO3atW0dEgAAAEq4AhVuExIS5Ovrm6O9atWq+vPPP/M1xq+//qrk5GT17NnT1JaVlaXdu3dr5cqVWrJkiTIyMpSammo26zY5OVk+Pj6SbsycjYuLMxs3KSlJksz63Gy7tY+rq2ues20BAABQsmzYsEG7du0yrW3r7OysBx54wPRDIRcAAABFrUCFWy8vLx05ciRH8fbw4cMqX758vsZ48MEHtXHjRrO2cePG6b777tMLL7ygKlWqyNnZWbGxsXrsscckScePH1dCQoKaNm0qSWratKkWLlyo5ORkeXl5SZJiYmLk6uqqunXrmvrc/jCJmJgY0xgAAABA/fr1Vb9+ffXv31/SjfvapUuX6q233lJ2drYOHTpk4wgBAABQ0hSocNulSxdNmzZN5cqVU8uWLSVJu3bt0vTp09WlS5d8jeHq6io/Pz+ztrJly6p8+fKm9l69eikqKkoeHh5ydXXV1KlTFRgYaCq6hoSEqG7duho9erTeeOMNJSYmas6cOerbt69cXFwkSU8//bRWrlypmTNnqlevXtqxY4c2b96sRYsWFeTUAQAAUAwZjUYdPHhQu3bt0s6dO/XLL7/o8uXL8vf3N93vAgAAAEWpQIXbESNG6I8//tDAgQPl5HRjiOzsbD3++ON67bXXrBZceHi4HBwcNHz4cKWnpyskJESTJk0y7Xd0dNTChQsVERGh3r17q0yZMgoNDdXw4cNNfapXr65FixYpMjJSy5cvV+XKlTV16lS1adPGanECAADg3vbAAw/oypUr8vf31wMPPKCnnnpKLVq0yPGgXAAAAKCoGIzGgj/e4sSJEzp8+LBKly4tPz8/VatWzZqx2VRi4iWrjWUw3HjacVJS0TwF+kTMuMI/iIVqB0fmu29R5+teR74sQ74sQ74sQ74sQ74sQ77y5uPj9o/H+OGHH9SiRQu5urpaISLbsOb9K5AXrkUAiiOubShq+b1/LdCM25tq167NgxoAAABwz3v44YdtHQIAAABgpkCF26ysLK1bt047duxQcnKysrOzzfYvX77cKsEBAAAAAAAAQElUoMLttGnTtH79erVt21b16tWTwWCwdlwAAAAAAAAAUGIVqHD75Zdfas6cOWrbtq214wEAAAAAAACAEs+hIC9ydnZWjRo1rB0LAAAAUGRCQ0N18eJFSdL8+fN19epVG0cEAAAA/E+BCrfPPfecli9fLiOP2gMAAMA96tixY6Zi7YIFC3TlypUiOW5WVpbmzJmjdu3aKSAgQO3bt9eCBQvM7q2NRqPmzp2rkJAQBQQEaODAgTp58mSRxAcAAAD7UKClEvbs2aOdO3fqv//9r+rVqycnJ/Nh5s+fb5XgAAAAgMLSoEEDjRs3Ts2bN5fRaNSSJUtUtmzZXPsOHTrUasddvHixVq1apRkzZqhu3bqKj4/XuHHj5Obmpv79+5v6rFixQlFRUfL19dXcuXMVFhamTZs2qVSpUlaLBQAAAParQIVbd3d3dejQwdqxAAAAAEUmMjJS7777rr7//nsZDAZt27ZNjo6OOfoZDAarFm737t2rRx99VA8//LAkydfXV19++aXi4uIk3Zhtu3z5cr300ktq3769JGnmzJkKDg7Wli1b1KVLlzzH5pnBKGw332O81wAUJ1zbYK8KVLiNjIy0dhwAAABAkbrvvvv0//7f/5Mk1a9fX0uXLpWXl1ehHzcwMFBr1qzRiRMnVLt2bR0+fFh79uzR2LFjJUlnz55VYmKigoODTa9xc3NTkyZNtHfv3jwLt56e5eToWKCV0ACLeXm52ToEALA6rm2wNwUq3EpSZmamdu3apdOnT6tr165ydXXVuXPn5OrqqnLlylkzRgAAAKBQHT58uMiONXjwYF2+fFmdOnWSo6OjsrKy9Nprr6l79+6SpMTEREnKUUT28vJSUlJSnuOmpKQxUwiFzmC4UdhITr4kHnkCoLjg2oai5u2dvz8SFKhw+8cff+j555/Xn3/+qfT0dLVu3Vqurq5avHix0tPT9dZbbxVkWAAAAMBmTp8+rWXLlunYsWOSpLp166p///6qUaOGVY+zefNmbdy4UbNnz1bdunV16NAhRUZGqmLFigoNDf1HY/NhE0XFaOT9BqD44doGe1Og71JNmzZNjRo10q5du8wejtChQwft2LHDasEBAAAARWHbtm3q3Lmz4uLi5O/vL39/f+3fv19dunTRTz/9ZNVjzZw5U4MHD1aXLl3k7++vHj16aMCAAVq0aJEkycfHR5KUnJxs9rrk5GR5e3tbNRYAAADYrwLNuN2zZ49WrVolFxcXs/Zq1arp3LlzVgkMAAAAKCqzZ8/WwIEDNWrUKLP2WbNmadasWWrdurXVjnXt2jUZblvTwNHRUcb/m+Lj6+srHx8fxcbGqkGDBpKky5cva//+/erTp4/V4gAAAIB9K1DhNjs7W9nZ2Tna//rrL9a3BQAAwD3n2LFjmjNnTo72Xr16admyZVY91iOPPKKFCxeqatWqpqUSoqOj1atXL0mSwWBQ//799d5776lmzZry9fXV3LlzVbFiRbVv396qsQAAAMB+Fahw27p1ay1btkxTpkwxtaWlpendd99V27ZtrRYcAAAAUBQ8PT116NAh1apVy6z90KFDOR4S9k9NmDBBc+fO1eTJk5WcnKyKFSuqd+/eeuWVV0x9XnjhBV29elUTJ05Uamqqmjdvrg8++MBsmTIAAAAUbwUq3I4dO1ZhYWHq3Lmz0tPTNWrUKJ08eVIVKlTQO++8Y+0YAQAAgEL15JNPauLEiTpz5oyaNWsmSfrll1+0ePFiDRw40KrHcnV11fjx4zV+/Pg8+xgMBo0YMUIjRoyw6rEBAABw7yhQ4bZy5cr67LPP9OWXX+rIkSO6cuWKnnjiCXXr1k2lS5e2dowAAABAoXrllVfk6uqqDz/80DQRoWLFiho6dKj69+9v4+gAAABQEhWocCtJTk5Oevzxx60ZCwqJw5/nzbazq1S0USQAAAD2yWAwaODAgRo4cKAuX74s6cbMWAAAAMBWClS43bBhwx339+jRoyDDAgAAADZHwRYAAAD2oECF22nTppltZ2Zm6urVq3J2dlaZMmUo3AIAAAAAAADAP1Cgwu3u3btztJ08eVIREREKCwv7x0EBAAAAAAAAQEnmYK2BatWqpZEjR+aYjQsAAAAAAAAAsIzVCrfSjQeWnT9//u4dAQAAADuRkZGhAQMG6OTJk7YOBQAAADAp0FIJW7duNds2Go1KTEzUypUr1axZM6sEBgAAABQFZ2dnHTlyxNZhAAAAAGYKVLh95ZVXzLYNBoM8PT314IMPasyYMVYJDAAAACgq3bt316effqpRo0bZOhQAAABAUgELt4cPH7Z2HAAAAIDNZGVladWqVYqJiVGjRo1UpkwZs/3jxo2zUWQAAAAoqQpUuAUAAACKk99++00NGzaUJJ04ccJsn8FgsEVIAAAAKOEKVLiNjIzMd19mJwAAAMDerVixwtYhAAAAAGYKVLg9ePCgDh06pMzMTNWuXVuSdPLkSTk4OJhmKkjMTgAAAMC95dSpUzp9+rRatmyp0qVLy2g0ck8LAAAAmyhQ4bZdu3YqV66cZsyYIQ8PD0nSxYsXNW7cOLVo0ULPPfecVYMEAAAACtPff/+tV199VTt37pTBYNA333yj6tWrKzw8XB4eHho7dqytQwQAAEAJ41CQF3344YcaOXKkqWgrSR4eHnr11Vf14YcfWi04AAAAoChERkbKyclJP/zwg0qXLm1q79y5s7Zt22bDyAAAAFBSFWjG7eXLl5WSkpKjPSUlRWlpaf84KAAAAKAo/fTTT1qyZIkqV65s1l6rVi0lJCTYKCoAAACUZAWacduhQweNGzdO33zzjf766y/99ddf+vrrrzV+/Hh17NjR2jECAAAAherKlStmM21vunDhglxcXGwQEQAAAEq6As24nTx5smbMmKGRI0cqMzNTkuTo6KgnnnhCo0ePtmqAAAAAQGFr0aKFNmzYoFdffdXUlp2drQ8++EBBQUG2CwwAAAAlVoEKt2XKlFFERIRGjx6t06dPS5Jq1KihsmXLWjU4AAAAoCi88cYbGjhwoOLj45WRkaG3335bR48e1cWLF7Vq1SpbhwcAAIASqEBLJdyUmJioxMRE1apVS2XLlpXRaLRWXAAAAECR8fPz09dff63mzZvr0Ucf1dWrV9WhQwetX79eNWrUsHV4AAAAKIEKNOP277//1quvvqqdO3fKYDDom2++UfXq1RUeHi4PDw+NHTvW2nECAAAAhcrNzU0vvfSSrcMAAAAAJBVwxm1kZKScnJz0ww8/mD3EoXPnztq2bZvVggMAAACKysWLF7VkyRKFh4crPDxcH374oS5cuGDrsAAAAFBCFahw+9NPP+mNN95Q5cqVzdpr1aqlhIQEqwQGAAAAFJXdu3erXbt2WrFihVJTU5WamqoVK1bo0Ucf1e7du20dHgAAAEqgAi2VcOXKFbOZtjdduHBBLi4u/zgoAAAAoCi99dZb6ty5syIiIuTo6ChJysrK0uTJk/XWW29p48aNNo4QAAAAJU2BZty2aNFCGzZsMGvLzs7WBx98oKCgIGvEBQAAABSZU6dOadCgQaairSQ5Ojpq4MCBOnXqlA0jAwAAQElVoBm3b7zxhgYOHKj4+HhlZGTo7bff1tGjR3Xx4kWtWrXK2jECAAAAhaphw4Y6fvy47rvvPrP248ePq379+jaKCgAAACVZgQq3fn5++vrrr/XRRx+pXLlyunLlijp06KC+ffuqYsWK1o4RAAAAsLrDhw+bfu/fv7+mTZumU6dOqUmTJpKk/fv3a+XKlRo1apStQgQAAEAJZnHhNiMjQ88//7wmT56sl156qTBiAgAAAApdjx49ZDAYZDQaTW1vv/12jn4jR45U586dizI0AAAAwPLCrbOzs44cOWKVg3/88cdatWqV/vjjD0lSvXr19PLLL6tt27aSpOvXrysqKkqbNm1Senq6QkJCNGnSJHl7e5vGSEhIUEREhHbu3KmyZcuqR48eGjlypJyc/ndqO3fuVFRUlH7//XdVqVJFL730knr27GmVcwAAAMC9aevWrbYOAQAAAMhTgZZK6N69uz799NN//LWxypUra9SoUapZs6aMRqM2bNigV155RevXr1e9evU0ffp0/fjjj5ozZ47c3Nw0ZcoUDR06VKtXr5Z040m/Q4YMkbe3t1avXq3z589rzJgxcnZ21uuvvy5JOnPmjIYMGaKnn35as2bNUmxsrCZMmCAfHx+1adPmH8UPAACAe1e1atVsHQIAAACQpwIVbrOysrRq1SrFxMSoUaNGKlOmjNn+cePG5Wucdu3amW2/9tprWrVqlfbt26fKlStr7dq1mjVrllq1aiVJmj59ujp37qx9+/apadOm2r59u44eParo6Gh5e3urQYMGGjFihGbNmqWhQ4fKxcVFq1evlq+vr8aOHStJqlOnjvbs2aOlS5dSuAUAAIDJuXPntGfPHqWkpCg7O9tsX//+/W0UFQAAAEoqiwq3Z86cUbVq1fTbb7+pYcOGkqQTJ06Y9TEYDAUKJCsrS1999ZWuXLmiwMBAxcfHKyMjQ8HBwaY+derUUdWqVU2F23379snPz89s6YSQkBBFRETo6NGjatiwofbt22cq/N7aZ/r06XeNqYCnkuc41hrvXmTJuZMvy5Avy5Avy5Avy5Avy5Avy5CvwrVu3TpNnDhRzs7OqlChgtk+g8FA4RYAAABFzqLCbceOHbV9+3atWLFCkvTqq69qwoQJZoVTSx05ckRPP/20rl+/rrJly2rBggWqW7euDh06JGdnZ7m7u5v19/LyUmJioiQpKSkpx7Fvbt+tz+XLl3Xt2jWVLl0617g8PcvJ0dGhwOeVGy8vN6uOl5ezLub/rNm3fcJzcinQROt/xNvb8nMvqnwVF+TLMuTLMuTLMuTLMuTLMuSrcMydO1evvPKKhgwZIgcH694DAgAAAAVhUQXv1ifuStJ///tfXb169R8FULt2bW3YsEGXLl3S119/rTFjxuijjz76R2NaQ0pKmlVn3Hp5uSk5+ZJuS2GhSE/PNNt2uO2gmbftLwpJSZfy3beo83WvI1+WIV+WIV+WIV+WIV+WIV95K8gfiG937do1denShaItAAAA7MY/mnp5eyG3IFxcXFSzZk1JUqNGjXTgwAEtX75cnTp1UkZGhlJTU81m3SYnJ8vHx0fSjZmzcXFxZuMlJSVJklmfm2239nF1dc1ztu1N1v5QZDRaf8x7RUHOuyTnqyDIl2XIl2XIl2XIl2XIl2XIV+Ho1auXvvrqKw0ePNjWoQAAAACSLCzcGgyGAq9hm1/Z2dlKT09Xo0aN5OzsrNjYWD322GOSpOPHjyshIUFNmzaVJDVt2lQLFy5UcnKyvLy8JEkxMTFydXVV3bp1TX3++9//mh0jJibGNAYAAAAwcuRIDRkyRNu2bZOfn5+cnMxvk/P78F0AAADAWixeKmHs2LFycXGRJKWnpysiIkJlypQx6zd//vx8jTd79mw99NBDqlKlitLS0vTFF19o165dWrJkidzc3NSrVy9FRUXJw8NDrq6umjp1qgIDA01F15CQENWtW1ejR4/WG2+8ocTERM2ZM0d9+/Y1xfj0009r5cqVmjlzpnr16qUdO3Zo8+bNWrRokSWnDgAAgGJs0aJF2r59u2rXrp1jX2FPXAAAAAByY1HhNjQ01Gy7e/fu/+jgycnJGjNmjM6fPy83Nzf5+/tryZIlat26tSQpPDxcDg4OGj58uNLT0xUSEqJJkyaZXu/o6KiFCxcqIiJCvXv3VpkyZRQaGqrhw4eb+lSvXl2LFi1SZGSkli9frsqVK2vq1Klq06bNP4odAAAAxUd0dLSmT5+unj17Fsnxzp07p7ffflvbtm3T1atXVbNmTU2fPl2NGzeWdGPCxLx58/Sf//xHqampatasmSIiIlSrVq0iiQ8AAAC2ZzBaY6HaYigxMf8P07obg+HGQzOSkormYSInYsy/yufw53mz7ewqFQs/iNvUDo7Md9+izte9jnxZhnxZhnxZhnxZhnxZhnzlzcfnnz+crHXr1lq5cmWRFEYvXryo0NBQBQUFqU+fPqpQoYJOnTqlGjVqqEaNGpKk999/X++//76ioqLk6+uruXPn6rffftOmTZtUqlSpXMe15v0rkBeuRQCKI65tKGr5vX/9Rw8nAwAAAIqD/v3766OPPtKECRMK/ViLFy9W5cqVFRn5vz9sV69e3fS70WjU8uXL9dJLL6l9+/aSpJkzZyo4OFhbtmxRly5d8hybVR1Q2G6+x3ivAShOuLbBXlG4BQAAQIkXFxenHTt26Pvvv1e9evVyPJwsv89wyI/vvvtOISEhGj58uHbv3q1KlSrpmWee0VNPPSVJOnv2rBITExUcHGx6jZubm5o0aaK9e/fmWbj19CwnR0cHq8UJ3ImX1z+f6Q4A9oZrG+wNhVsAAACUeO7u7urYsWORHOvMmTNatWqVBg0apBdffFEHDhzQ1KlT5ezsrNDQUCUmJkqSvLy8zF7n5eWlpKSkPMdNSUljphAKncFwo7CRnMzXiQEUH1zbUNS8vVkqAQAAAMiXW5ctKGxGo1GNGjXS66+/Lklq2LChfv/9d61evTrHw4AtH9saEQJ3ZzTyfgNQ/HBtg73hu1QAAABAEfLx8VGdOnXM2u677z4lJCSY9ktScnKyWZ/k5GR5e3sXTZAAAACwOWbcAgAAoMRr166dDHdYZ2Dr1q1WO1azZs104sQJs7aTJ0+qWrVqkiRfX1/5+PgoNjZWDRo0kCRdvnxZ+/fvV58+fawWBwAAAOwbhVsAAACUeAMGDDDbzszM1MGDB7V9+3aFhYVZ/Vh9+vTRwoUL1alTJ8XFxWnNmjV66623JEkGg0H9+/fXe++9p5o1a8rX11dz585VxYoV1b59e6vGAgAAAPtF4RYAAAAl3u2F25tWrlyp+Ph4qx4rICBA8+fP1zvvvKMFCxbI19dX4eHh6t69u6nPCy+8oKtXr2rixIlKTU1V8+bN9cEHH6hUqVJWjQUAAAD2i8ItAAAAkIeHHnpIs2fPtvrDyx555BE98sgjee43GAwaMWKERowYYdXjAgAA4N7Bw8kAAACAPHz11VcqX768rcMAAABACcSMWwAAAJR4PXr0MHs4mdFoVFJSklJSUjRp0iQbRgYAAICSisItAAAASrzbH/plMBjk6empBx54QHXq1LFRVAAAACjJKNwCAACgxBs6dKitQwAAAADMsMYtAAAAAAAAANgZZtwCAACgxKpfv77Z2ra5MRgMOnjwYBFFBAAAANxA4RYAAAAl1vz58/Pct2/fPq1YsULZ2dlFGBEAAABwA4VbAAAAlFi3P5RMko4fP67Zs2fr+++/V7du3TR8+HAbRAYAAICSjsItAAAAIOncuXN69913tWHDBoWEhGjDhg3y8/OzdVgAAAAooSjcAgAAoES7dOmSFi5cqI8++kgNGjTQ0qVL1aJFC1uHBQAAgBKOwi0AAABKrMWLF+uDDz6Qt7e3Zs+enevSCQAAAIAtULgFAABAiTV79myVLl1aNWrU0IYNG7Rhw4Zc+93pIWYAAABAYaBwCwAAgBKrR48eMhgMtg4DAAAAyIHCLQAAAEqsqKgoW4cAAAAA5MrB1gEAAAAAAAAAAMxRuAUAAAAAAAAAO0PhFgAAAAAAAADsDIVbAAAAAAAAALAzFG4BAAAAAAAAwM5QuAUAAAAAAAAAO0PhFgAAAAAAAADsDIVbAAAAAAAAALAzFG4BAAAAAAAAwM5QuAUAAAAAAAAAO0PhFgAAAAAAAADsDIVbAAAAAAAAALAzTrYOAEXP4c/zOdqyq1S0QSQAAAAAAAAAcsOMWwAAAAAAAACwMxRuAQAAAAAAAMDOULgFAAAAAAAAADtD4RYAAAAAAAAA7AyFWwAAAAAAAACwMxRuAQAAAAAAAMDOULgFAAAAAAAAADvjZOsAYB8c/jxvtp1dpaKNIgEAAAAAAABg0xm3ixYtUq9evRQYGKhWrVrp5Zdf1vHjx836XL9+XZMnT1ZQUJACAwM1bNgwJSUlmfVJSEjQ4MGD1aRJE7Vq1UozZsxQZmamWZ+dO3cqNDRUjRo1UocOHbRu3bpCPz8AAAAAAAAAKAibFm537dqlvn37as2aNYqOjlZmZqbCwsJ05coVU5/p06fr+++/15w5c7RixQqdP39eQ4cONe3PysrSkCFDlJGRodWrVysqKkrr16/XvHnzTH3OnDmjIUOGKCgoSJ999pkGDBigCRMmaNu2bUV6vgAAAAAAAACQHzZdKmHJkiVm21FRUWrVqpV+/fVXtWzZUpcuXdLatWs1a9YstWrVStKNQm7nzp21b98+NW3aVNu3b9fRo0cVHR0tb29vNWjQQCNGjNCsWbM0dOhQubi4aPXq1fL19dXYsWMlSXXq1NGePXu0dOlStWnTpsjPOzcnYsbZOgQAAADYwPvvv6/Zs2erf//+Gj9+vKQb3zqLiorSpk2blJ6erpCQEE2aNEne3t42jhYAAABFxa7WuL106ZIkycPDQ5IUHx+vjIwMBQcHm/rUqVNHVatWNRVu9+3bJz8/P7Ob2JCQEEVEROjo0aNq2LCh9u3bZyr83tpn+vTpd4zHYLDOed0cx1rj3YssOXfyZRnyZRnyZRnyZRnyZRnyZRnyVTzFxcVp9erV8vf3N2ufPn26fvzxR82ZM0dubm6aMmWKhg4dqtWrV9soUgAAiqesrCzt3BmjK1cuqmxZDwUFBcvR0dHWYQGS7Khwm52drenTp6tZs2by8/OTJCUlJcnZ2Vnu7u5mfb28vJSYmGjqc/vMg5vbd+tz+fJlXbt2TaVLl84Rj6dnOTk6WnclCS8vtzz3nXUpvH+K7AJ8wnOycjze3nmfe17ulC/kRL4sQ74sQ74sQ74sQ74sQ76Kj7S0NL3xxhuaOnWq3nvvPVN7fr51lhcK+yhs/BEJQHHyxRefa9Kk8Tp9+pSprUaNmpo8eZq6du1uw8iAG+ymcDt58mT9/vvv+vjjj20diiQpJSXNqjNuvbzclJx8SUZj7n3S0zNz32EFDnkd9A4yrRxPUtKlfPfNT77wP+TLMuTLMuTLMuTLMuTLMuQrbwX5A7E9eOutt9S2bVsFBwebFW7z862z3BTGxAPgVllZWdq2bZv+/PNPValSRW3atGFWGoB71rp16/Tcc8+qa9eu+uST1WrUqJHi4+M1ffp0Pffcs/r000/Vs2dPW4eJEs4uCrdvvfWWfvjhB3300UeqXLmyqd3b21sZGRlKTU01m3WbnJwsHx8fU5+4uDiz8ZKSkiTJrM/Ntlv7uLq65jrb9iZrfygyGq0/5r2iIOddkvNVEOTLMuTLMuTLMuTLMuTLMuSrePjyyy918OBBffrppzn25edbZ7mx5sQD4HbMSgNQnGRlZem1115Xx47/0gcfrJCjo4NcXV1Vr979+uCDFerfv49ef32kWrduxx+oUCjyO/HApn+SNxqNeuutt/Ttt99q2bJlql69utn+Ro0aydnZWbGxsaa248ePKyEhwTTToGnTpvrtt9+UnJxs6hMTEyNXV1fVrVvX1GfHjh1mY8fExNzxa2YAAABAYfjzzz81bdo0vf322ypVqpRVx75Z2OeHH2v+bNz4uZ577lk1aNBQmzdv0aVLl7R58xY1aNBQzz33rDZu/NzmMfLDDz/8WPITGxuj06dPacSIkTIYHGQ0/u//owaDg4YPf12nTp1UbGyMzWPlp3j+5JdNC7eTJ0/W559/rtmzZ6tcuXJKTExUYmKirl27Jklyc3NTr169FBUVpR07dig+Pl7h4eEKDAw0FV1DQkJUt25djR49WocPH9a2bds0Z84c9e3bVy4uLpKkp59+WmfOnNHMmTN17NgxrVy5Ups3b9bAgQNtdOYAAAAoqX799VclJyerZ8+eatiwoRo2bKhdu3ZpxYoVatiwodm3zm5167fOgKKSlZWliIjx6tjxX1q2bJVatHhArq6uatHiAS1btkodO/5LERETlJWVZetQASDfzp37S5JUv37DXPc3aNDQrB9gKzZdKmHVqlWSpGeffdasPTIy0rSOSHh4uBwcHDR8+HClp6crJCREkyZNMvV1dHTUwoULFRERod69e6tMmTIKDQ3V8OHDTX2qV6+uRYsWKTIyUsuXL1flypU1depUtWnTpgjOEgAAAPifBx98UBs3bjRrGzdunO677z698MILqlKliulbZ4899piknN86A4rKjh03ZqUtXLhEDg7m835ufE57XV26dNCOHTFq3ZrPVwDuDZUq3Vim8/Dhg2rR4oEc+w8dOmjWD7AVmxZujxw5ctc+pUqV0qRJk8yKtberVq2aFi9efMdxgoKCtGHDBktDBAAAAKzK1dVVfn5+Zm1ly5ZV+fLlTe03v3Xm4eEhV1dXTZ061exbZ0BRYVYagOLowQeDVaNGTc2dO1vLlq0ye7hndna25s17RzVq1NKDDwbfYRSg8PHYWQAAAMDOhIeH6+GHH9bw4cPVr18/eXt7691337V1WCiBbp2VlhtmpQG4Fzk6OioiYpq++eYrDRjQR7t379SlS5e0e/dODRjQR99885UiIqbyYDLYnE1n3AIAAACQVqxYYbadn2+dAUWBWWkAiquuXbtryZIViogYr86dO5jaa9SopSVLVqhr1+42jA64gcItAAAAACBXN2elhYU9qwED+mjEiNcVEhKk3bt3au7cd/TNN19pyZIVzEoDcE/q2rW7OnXqop07Y3TlykWVLeuhoKBgrmmwGxRuAQAAAAB5YlYagOLM0dFRrVu3kbe3m5KSLslotHVEwP9QuAUAAAAA3BGz0gAAKHoUbgEAAAAAd8WsNAAAipbD3bsAAAAAAAAAAIoShVsAAAAAAAAAsDMUbgEAAAAAAADAzlC4BQAAAAAAAAA7Q+EWAAAAAAAAAOyMk60DAAAAAAAAAGwhKytLO3fG6MqViypb1kNBQcFydHS0dViAJAq3AAAAAAAAKIG++OJzRUSM1+nTp0xtNWrUVETENHXt2t2GkQE3ULhFrhz+PJ+jLbtKRRtEAgAAAAAAYF1ffPG5wsKeVYcOj+mVV4bJx8dTiYkp2rp1i8LCntWSJSso3sLmKNwCAAAAAACgxMjKylJExHg1adJUhw4d1DfffGXaV716DTVp0lQRERPUqVMXlk2ATfFwMgAAAAAAAJQYO3bE6PTpU9q/f58aNrxfmzdv0aVLl7R58xY1bHi/9u/fp9OnT2rHjhhbh4oSjsItAAAAAOCusrKy9NNP27Rq1Sr99NM2ZWVl2TokACiQP/9MkCS1a9deH374ka5fv66NGzfq+vXr+vDDj9SuXXuzfoCtsFQCAAAAAOCOeIAPgOIkOTlJ0o1lEVq1apbj2vbww4+a9QNshcItAAAAACBP5g/wGS4fnwpKTPxbW7d+ywN8ANyTvLy8JUlLly7J8XCyLVu+1fLlH5r1A2yFwi0AAAAAIFc8wAdAcVSpUmXT79u2/Vfffvu1abt06TK59gNsgTVuAQAAAAC5uvkAn3379ub6AJ99+/byAB8A9xyj0Xjr1u178+gHFD1m3AIAAAAAcnXzwTyPPtpBH374kXbv3qGNGzeqbFkPffjhR+rf/2lt3fotD/ABcE85f/6c6ffWrR9SmTKldeXKZZUt66qrV69p69ZvcvQDbIHCLQAAAAAgV3d/gE87s34AcC+4ec26//7GpiLtrRo2bKSDB+O5tsHmWCoBAAAAAJCrWx/gU79+A7OlEurXb6Dly6PN+gHAveDmNevXXw/Iy8tLjz8eqkGDBunxx0Pl5eWlgwfjzfoBtsKMWwAAAABAripWrGS2bTQaTT936gcA9szb28f0e1raFX322XrT9q0PJ7u1H2ALzLgFAAAAAOTKYDBIkurV89OhQwfVuXMHubu7q3PnDjp8+JDq1fMz6wcA94JDh341/X77H6Ju3b61H2ALzLgFAAAAAOQqMfG8JOn3339T6dKlzfadP39O165dM+sHAPeCkydPmH6//e9Ot27f2g+wBWbcAgAAAAByValSZdPvt8+qvXX71n4AYO9uvX7d6drGtwlgaxRuAQAAAAC5atkySI6OjvLxqaj4+KN67rkX1LFjRz333AuKjz8qH5+KcnR0UsuWQbYOFQDyrWnTZpIkZ2dn7d17SJ06dVHjxo3VqVMX7d17SM7Ozmb9AFthqQQAAAAAQK52796prKwsJSaeV5061cz2ffjhYrN+rVu3KerwAKBALl68IEnKyMhQ/fq1TO0HDhzQ5s1f5ugH2AozbgEAAAAAuTp37i/T7w4O5h8fb92+tR8A2DsvL2+r9gMKC4VbAAAAAECuPD29JElOTk7Kzs4225ednS0nJyezfgBwL/D09LRqP6CwULgFAAAAAOTq4MFfJUmZmZlycXHR8OGv6ejRoxo+/DW5uLgoMzPTrB8A3As2b95k1X5AYaFwCwAAAADI1YkTx0y/t2nzsKpWraYff/xRVatWU5s2D+faDwDs3aFD8abf/f0bmu27dfvWfoAt8HAyAAAAAECuDh06KEmqUaOmfvhhq7Zu/ca0z9HRSdWr19CZM6dN/QDgXrB37y+m348cMb9+3bp9az/AFphxCwAAAADIVenSpSVJp0+fUnBwG1WoUEGlSpVShQoVFBwcojNnTpv1A4B7QVZWllX7AYWFwi0AAAAAIFe1a9cx/b5t2w/6+++/df36df3999/atu2HXPsBgL1zdnaxaj+gsFC4BQAAAADkqlOnzlbtBwD24Pr1a1btBxQWCrcAAAAAgFydPn3aqv0AwB6VLl1aDRo0YNkX2B0KtwAAAEARWrRokXr16qXAwEC1atVKL7/8so4fP27W5/r165o8ebKCgoIUGBioYcOGKSkpyUYRoyR7++1Iq/YDAHt07do1HTp0SNeuMcMW9oXCLQAAAFCEdu3apb59+2rNmjWKjo5WZmamwsLCdOXKFVOf6dOn6/vvv9ecOXO0YsUKnT9/XkOHDrVh1CipLlz42/T7okUfmu27dfvWfgBwL/noo//Iw6O8nJyc5OFRXh999B9bhwSYONk6AFiXw5/ni2zs7CoVC+1YAAAAxdWSJUvMtqOiotSqVSv9+uuvatmypS5duqS1a9dq1qxZatWqlaQbhdzOnTtr3759atq0aZ5jGwyFGTlKooyMDNPvQ4Y8Z7bv1u2MjAzefwDszsmTJ3Tx4sU79unX70lJUnBwsGJiYkzbN8XF7cv1dR4eHqpVq7ZV4gTyQuEWAAAAsKFLly5JuvEBUJLi4+OVkZGh4OBgU586deqoatWqdyzcenqWk6MjX6iDdTk6OiorKytf/by93YogIgDIn6SkJAUFBSo7Oztf/WNiYnJtb9/+oVzbHR0d9ddff8nb27vAMQJ3Q+EWAAAAsJHs7GxNnz5dzZo1k5+fn6QbHzSdnZ3l7u5u1tfLy0uJiYl5jpWSksaMR1ids7OzWeG2evXq6tWrl9auXaszZ86Y9UtKumSLEAEgD6W0c+fePGfc5lWQvdWWLf/Nc9+NP7iW4tqHAsnvHzsp3AIAAAA2MnnyZP3+++/6+OOPrTKe0WiVYQCT2x/Uc+bMGc2ZMyfXfrz/ANibmjXzXsrg/PlUVazofsf9d8N1D4XNpt+l2r17t1588UWFhITI399fW7ZsMdtvNBo1d+5chYSEKCAgQAMHDtTJkyfN+ly4cEEjR45Us2bN1KJFC4WHhystLc2sz+HDh/XMM8+ocePGatu2rRYvXlzYpwYAAADc0VtvvaUffvhBy5YtU+XKlU3t3t7eysjIUGqq+QfG5ORk+fj4FHWYwG0McnZ2lsT0bgD3vvPnUxUV9Y5ZW1TUO/kq2gJFwaYzbq9cuSJ/f3/16tUr16fkLl68WCtWrFBUVJR8fX01d+5chYWFadOmTSpVqpQkadSoUUpMTFR0dLQyMjIUHh6uiRMnavbs2ZKky5cvKywsTK1atdLkyZP122+/KTw8XO7u7urdu3eRni8AAABgNBo1ZcoUffvtt1qxYoWqV69utr9Ro0ZydnZWbGysHnvsMUnS8ePHlZCQcMcHkwH/xMmTJ5SaeucH+NxgNHtg2a3yeoCPuzsP8AFgv5577nm98MLzKlvWWVeuZCgfy3oDRcamhdu2bduqbdu2ue4zGo1avny5XnrpJbVv316SNHPmTAUHB2vLli3q0qWLjh07pm3btunTTz9V48aNJUkTJkzQ4MGDNXr0aFWqVEmff/65MjIyNH36dLm4uKhevXo6dOiQoqOj71q4tdYaYTfHKclrjlly7uTLMuTLMuTLMuTLMuTLMuTLMuSr+Jg8ebK++OIL/fvf/1a5cuVM69a6ubmpdOnScnNzU69evRQVFSUPDw+5urpq6tSpCgwMpHCLQpGcnKwHH8z/A3zycqcH+MTHH5WXl9c/Gh8AgJLGbte4PXv2rBITE82epuvm5qYmTZpo79696tKli/bu3St3d3dT0VaSgoOD5eDgoLi4OHXo0EH79u1TixYt5OLiYuoTEhKixYsX6+LFi6an996uMJ7K6+WV98LDZ12s80+RXYSf5pwsiLkgT5i9U76QE/myDPmyDPmyDPmyDPmyDPm6961atUqS9Oyzz5q1R0ZGqmfPnpKk8PBwOTg4aPjw4UpPT1dISIgmTZpU5LGiZPDy8tKOHXvznHF7e0G2Xbt2+u6778za7vQAH3d3D4q2AAAUgN0Wbm/OPLj9f/BeXl5KSkqSdOOJu56enmb7nZyc5OHhYXp9UlKSfH19zfp4e3ub9uVVuLXmU3kNhhsfspKTL+W5cHV6eqZVjuVQhCtjZ1oQsyVPWcxPvvA/5Msy5Msy5Msy5Msy5Msy5CtvBfkDsS0dOXLkrn1KlSqlSZMmUaxFkbnTUga3P8Dn9qIta0ECAFA47LZwaw+s/aHIaCxeTxx0+PN8jrbsKhVz7VuQ8y5u+Sps5Msy5Msy5Msy5Msy5Msy5AuALZw/n6rY2Fg9/vhjprbPPvtarVq1smFUAAAUb3ZbuL35xNzk5GRVrPi/YmBycrLq168v6cbM2ZSUFLPXZWZm6uLFi6bXe3t7m2bo3nRz++bMWwAAAADAnbVq1UrJyak8wAcAgCJi3UVcrcjX11c+Pj6KjY01tV2+fFn79+9XYGCgJCkwMFCpqamKj4839dmxY4eys7MVEBAgSWratKl+/vlnsyefxsTEqHbt2nkukwAAAAAAAAAAtmTTwm1aWpoOHTqkQ4cOSbrxQLJDhw4pISFBBoNB/fv313vvvaetW7fqyJEjGj16tCpWrKj27dtLkurUqaM2bdrozTffVFxcnPbs2aMpU6aoS5cuqlSpkiSpW7ducnZ21vjx4/X7779r06ZNWr58uQYNGmSz8wYAAAAAAACAO7HpUgnx8fHq37+/aTsyMlKSFBoaqqioKL3wwgu6evWqJk6cqNTUVDVv3lwffPCBSpUqZXrNrFmzNGXKFA0YMEAODg7q2LGjJkyYYNrv5uamJUuW6K233lLPnj1VoUIFvfzyy+rdu3fRnSgAAAAAAAAAWMCmhdugoKA7PlXXYDBoxIgRGjFiRJ59ypcvr9mzZ9/xOPXr19fHH39c4DgBAAAAAAAAoCjZ7Rq3AAAAAAAAAFBSUbgFAAAAAAAAADtj06USAAAAAAAAgPwwGG78FMa4N//rUEhTHI3GGz+AJSjc3sMc/jxv6xAAAAAAAAAKncEgubo6F+oxypQp3PEvX86geAuLULgFAAAAAACAXbs5K/bq1UxlZ1u3+mkwSB4eZXXx4pVCKaw6OBhUpoyTDAZm3cIyFG4BAAAAoJjh68QAiqvsbKOys607psEgOTo6Kju7sK4/XNRQMBRuAQAAAKAY4evEAAAUDxRuAQAAAKAY4evEAAAUDxRuUSROxIyzqP9ZFyelp2fmuq92cKQ1QgIAAACKNb5ODADAvY3CLQAAAAAUM2lpaUpKulgohdvMzDRduFBYM24lyUOSi/UHB3DP49qGkobCLQAAAAAUMwcOHNCuXbtsHUaBPPDAA2rcuLmtwwBgh7i2oaShcAsAAAAAxUzjxo1VpUqNQpmVVr582UKdlebt7WH9gQEUC1zbUNJQuAUAAACAYqZcuXKSXAqluOHt7SYnp0uFVtwoV85ZaWkZ1h8cwD2PaxtKGgdbBwAAAAAAAAAAMMeMWwAAAAAohhwdDZKsO3XMYJCysrLk4KBCmpVmsP6gAIoVrm0oSSjcAgAAAECxcqNAULp04Xzcy8jIUNmyzoUy9k2FUTgBcK/j2oaSh8ItAAAAABQj2dlGpaVlytoz0qQb6zSWKeOsq1czrL7G5E1GI8UNADlxbUNJROEWAAAAAIqZ7OzCqQ4Y/u/bvkajCq24AQB54dqGkoaHkwEAAAAAAACAnWHG7T3E4c/ztg4BAAAAAAAAQBFgxi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BkKtwAAAAAAAABgZyjcAgAAAAAAAICdoXALAAAAAAAAAHaGwi0AAAAAAAAA2BknWwcAAAAAALCtkydPKDX14l37OThIpUs76dq1TGVn529sd3cP1apV+x9GCACW49qGex2FWzvl8Od5W4cAAAAAoARITk7Wgw8GKju/1QoLOTo6Kj7+qLy8vAplfADIDdc2FAcUbgEAAAA7tXLlSi1ZskSJiYmqX7++3nzzTQUEBNg6LBQzXl5e2rFjb75mpUlS+fJldeHClXyP7+7uQWEDQJHj2obigMItAAAAYIc2bdqkyMhITZ48WU2aNNGyZcsUFhamr776ig+KsLr8ft3XYJC8vd2UlHRJRmMhBwUA/xDXNtzrKNzaCZZGAAAAwK2io6P11FNPqVevXpKkyZMn64cfftDatWs1ePDgXF9jMBRlhCiJbr7HeK8BKE64tsFeUbgFAAAA7Ex6erp+/fVXDRkyxNTm4OCg4OBg7d27N9fXeHqWk6OjQ1GFiBLOy8vN1iEAgNVxbYO9oXALAAAA2Jm///5bWVlZOZZE8PLy0vHjx3N9TUpKGjOFUOgMhhuFjeRkvk4MoPjg2oai5u2dvz8SULgFAAAAigk+bKKoGI283wAUP1zbYG/4LhUAAABgZypUqCBHR0clJyebtScnJ8vb29tGUQEAAKAoUbgFAAAA7IyLi4vuv/9+xcbGmtqys7MVGxurwMBAG0YGAACAosJSCbAqhz/P52jLrlLRBpEAAADc2wYNGqQxY8aoUaNGCggI0LJly3T16lX17NnT1qEBAACgCFC4BQAAAOxQ586dlZKSonnz5ikxMVENGjTQBx98wFIJAAAAJQSFWwAAAMBO9evXT/369bN1GAAAALAB1rgFAAAAAAAAADvDjFsUutvXvWXNWwAAAAAAAODOStSM25UrV6pdu3Zq3LixnnzyScXFxdk6JAAAAAAAAADIocQUbjdt2qTIyEi98sorWr9+verXr6+wsDAlJyfbOjQAAAAAAAAAMFNilkqIjo7WU089pV69ekmSJk+erB9++EFr167V4MGDbRxdyXL70gmSZcsnnIgZZ7VYagdHWm0sAAAAAAAAwFpKROE2PT1dv/76q4YMGWJqc3BwUHBwsPbu3Zvn6wwG6xz/5jjWGq84yrEOrsEgB6PRvO224m5uBeDb3a0gbM0i8H2tbVME5v1lGfJlGfJlGfJlGfJlGfIFAAAAlCwlonD7999/KysrS15eXmbtXl5eOn78eK6v8fFxs3ocXl55j+n94hqrHw8ly53eX8iJfFmGfFmGfFmGfFmGfCEvhXH/CuTF25v3G4Dih2sb7E2JWeMWAAAAAAAAAO4VJaJwW6FCBTk6OuZ4EFlycrK8vb1tFBUAAAAAAAAA5K5EFG5dXFx0//33KzY21tSWnZ2t2NhYBQYG2jAyAAAAAAAAAMipRKxxK0mDBg3SmDFj1KhRIwUEBGjZsmW6evWqevbsaevQAAAAAAAAAMBMiSncdu7cWSkpKZo3b54SExPVoEEDffDBByyVAAAAAAAAAMDulIilEm7q16+fvv/+e8XHx+s///mPmjRpUiTHXblypdq1a6fGjRvrySefVFxcXJEc154tWrRIvXr1UmBgoFq1aqWXX35Zx48fN+tz/fp1TZ48WUFBQQoMDNSwYcOUlJRko4jty/vvvy9/f39NmzbN1Ea+zJ07d06jRo1SUFCQAgIC1K1bNx04cMC032g0au7cuQoJCVFAQIAGDhyokydP2i5gG8rKytKcOXPUrl07BQQEqH379lqwYIGMRqOpT0nO1+7du/Xiiy8qJCRE/v7+2rJli9n+/OTmwoULGjlypJo1a6YWLVooPDxcaWlpRXgWRedO+crIyNDbb7+tbt26qWnTpgoJCdHo0aN17tw5szHIV+4mTpwof39/LV261Ky9JOULgO3x2QZAcWPJ/RhQ1EpU4dYWNm3apMjISL3yyitav3696tevr7CwsBwPSitpdu3apb59+2rNmjWK/v/t3XtYTfn+B/B3V7dSUY0hk0SbbLqc3LqIGGYmnSHHmGYU6SAiSTNJmS5uuZOMshG5nmYYzKTxaDCTEZ0u7jUuITQelVGqSbf1+8Npja2kRLvfeL+ex/O0v2ut7/rsj3bPd332d31XTAwqKyvh4eGB0tJScZ+lS5fixIkTWLduHXbu3IkHDx5g1qxZCoy6Zbhw4QL27dsHiUQi1858/aWwsBAuLi5QU1ODTCZDfHw8/P39oaWlJe4jk8mwc+dOhISEIC4uDm3atIGHhweePHmiwMgVQyaTYe/evfjqq69w5MgR+Pn5YcuWLdi5c6fcPm9rvkpLSyGRSBAcHFzn9obkxs/PD9evX0dMTAyioqKQmpqKr776qrneQrOqL19lZWW4cuUKZsyYgQMHDiAyMhI3b97EjBkz5PZjvmo7duwYzp8/D319/Vrb3qZ8EZFi8dqGiP6OGjoeI1IIgd6of/3rX0JoaKj4uqqqSrC1tRWio6MVGFXLU1BQIJiYmAgpKSmCIAhCUVGR0KdPHyEhIUHc5/r164KJiYmQkZGhoCgVr7i4WBg5cqTw66+/ChMnThQWL14sCALz9byVK1cKLi4uL9xeXV0t2NjYCFu2bBHbioqKBKlUKvzwww/NEWKLMm3aNCEgIECubdasWcK8efMEQWC+nmViYiIcO3ZMfN2Q3NR8Fi9cuCDu8/PPPwsSiUS4f/9+8wWvAM/nqy7nz58XTExMhHv37gmCwHzVla/79+8LdnZ2wtWrV4Vhw4YJMTEx4ra3OV9E1Px4bUNEf3cNGb8SNSfOuH2DysvLcfnyZVhbW4ttysrKsLa2RkZGhgIja3keP34MAOKMyEuXLqGiokIud8bGxujcuTPOnTuniBBbhLCwMNjb28vlBWC+nnf8+HFIpVJ4e3tj8ODBGDNmDOLi4sTtd+/eRV5enly+NDU1YWZm9lZ+Ni0sLHDmzBncvHkTAJCVlYW0tDQMGTIEAPNVn4bkJiMjA+3bt0ffvn3FfaytraGsrMzbSwEUFxdDSUkJ7du3B8B8Pa+6uhpffPEFPDw80LNnz1rbmS8iai68tiEiImp+b83DyRThjz/+QFVVFTp27CjX3rFjx1rrub7NqqursXTpUlhaWsLExAQAkJ+fDzU1NfFCvkbHjh2Rl5eniDAVLj4+HleuXMG3335baxvzJe/OnTvYu3cv3N3d4enpiYsXL2Lx4sVQU1PD2LFjxZzU9dl8G9cFnjZtGoqLi/Hhhx9CRUUFVVVVmDt3Lv75z38CAPNVj4bkJj8/Hx06dJDbrqqqCi0trbfy8/msJ0+eYNWqVXB0dISGhgYA5ut5MpkMqqqqcHNzq3M780VEzYXXNkRERM2PhVtSuNDQUFy7dg179uxRdCgt1u+//44lS5Zg27ZtaNWqlaLDafEEQYBUKoWvry8AwNTUFNeuXcO+ffswduxYBUfX8iQkJOD777/H6tWr0aNHD2RmZmLZsmXQ19dnvuiNqaiowJw5cyAIAkJDQxUdTot06dIlxMbG4sCBA1BSUlJ0OERERERE1My4VMIbpKOjAxUVlVqL9RcUFEBXV1dBUbUsYWFhOHnyJHbs2IFOnTqJ7bq6uqioqEBRUZHc/gUFBdDT02vuMBXu8uXLKCgogLOzM0xNTWFqaoqUlBTs3LkTpqamzNdz9PT0YGxsLNfWvXt35ObmitsB8LP5PytWrMC0adPg6OgIiUSCMWPGYNKkSYiOjgbAfNWnIbnR1dXFw4cP5bZXVlaisLDwrfx8Ak+Ltj4+PsjNzcW2bdvE2bYA8/Ws1NRUFBQUYNiwYeLf/nv37mH58uVwcHAAwHwRUfPhtQ0REVHzY+H2DVJXV0efPn2QnJwstlVXVyM5ORkWFhYKjEzxBEFAWFgYjh07hh07dqBr165y26VSKdTU1ORyl52djdzcXJibmzdztIo3aNAgfP/99zh48KD4TyqVwsnJSfyZ+fqLpaWluF5rjVu3bqFLly4AAAMDA+jp6cnlq7i4GOfPn38rP5tlZWW1ZvOpqKhAEAQAzFd9GpIbCwsLFBUV4dKlS+I+Z86cQXV1Nfr169fsMStaTdH29u3b2L59O3R0dOS2M19/+fjjj3H48GG5v/36+vrw8PDAli1bADBfRNR8eG1DRETU/LhUwhvm7u4Of39/SKVS9OvXDzt27MCff/4JZ2dnRYemUKGhofjhhx/w9ddfo127duI6fJqammjdujU0NTUxbtw4hIeHQ0tLCxoaGli8eDEsLCzeykKkhoaGuP5vjbZt20JbW1tsZ77+MmnSJLi4uCAqKgoffvghLly4gLi4OISFhQEAlJSU4Obmhk2bNsHQ0BAGBgZYv3499PX1MWLECAVH3/yGDRuGqKgodO7cWVwqISYmBuPGjQPAfJWUlCAnJ0d8fffuXWRmZkJLSwudO3d+aW6MjY1hZ2eHhQsXIjQ0FBUVFVi0aBEcHR3xzjvvKOptvTH15UtPTw/e3t64cuUKoqOjUVVVJf7919LSgrq6OvP13O/X84VtNTU16Orqonv37gDevt8vIlIsXtsQ0d/Ry8ZjRIqkJNRMqaI3ZteuXdi6dSvy8vLQu3dvBAUFwczMTNFhKZREIqmzfdmyZeLA78mTJwgPD0d8fDzKy8tha2uL4OBg3vr5P66urujVqxcCAwMBMF/PO3HiBNasWYNbt27BwMAA7u7u+OSTT8TtgiAgIiICcXFxKCoqwj/+8Q8EBwfDyMhIgVErRnFxMdavX4/ExEQUFBRAX18fjo6O8PLygrq6OoC3O19nz56t88FQY8eORXh4eINy8+jRIyxatAjHjx+HsrIyRo4ciaCgILRr164530qzqC9fs2bNwvDhw+s8LjY2FgMHDgTAfAF//X49z8HBAW5ubpg8ebLY9jbli4gUj9c2RPR309jxGFFzYuGWiIiIiIiIiIiIqIXhGrdERERERERERERELQwLt0REREREREREREQtDAu3RERERERERERERC0MC7dERERERERERERELQwLt0REREREREREREQtDAu3RERERERERERERC0MC7dERERERERERERELQwLt0REREREREREREQtDAu3REQKdvfuXUgkEmRmZio6FNGNGzfwySefoG/fvvj4448VHY6cAwcOwMrKStFhEBEREb0yiUSCxMREhZ0/OzsbNjY2KC4uVlgMr4uDgwO2b9+u6DDemNfx/srLy+Hg4ICLFy++nqCIqNmwcEtEb7358+dDIpFg8+bNcu2JiYmQSCQKikqxNmzYgDZt2uDHH3/8Ww+EiYiIiF63vLw8LFq0CMOHD4dUKoW9vT08PT2RnJys6NBEa9aswcSJE6GhoSG2ZWVl4bPPPkPfvn1hb28PmUzWpHM4ODhAIpFAIpHAzMwMTk5O+Oabb5oa+muxePFiODs7QyqVvpZJCg8fPkRwcDCGDh0KqVQKGxsbeHh4IC0trcF9vGhywrfffosJEyY0KT51dXVMmTIFq1atalI/RNT8VBUdABFRS9CqVSvIZDJMmDABWlpaig7ntSgvL4e6uvorHZuTk4OhQ4eiS5curzmqhmtK/ERERESKcPfuXbi4uKB9+/b48ssvYWJigsrKSpw6dQqhoaH48ccfFR0icnNzcfLkSSxcuFBsKy4uhoeHBwYPHozQ0FBcvXoVCxYsQPv27ZtUNPT29sYnn3yCsrIyJCQkICgoCPr6+rC3t38db6VJxo0bh/Pnz+O3335rcl+zZ89GRUUFwsPD0bVrVxQUFCA5ORmPHj1qct8dOnSod3tFRQXU1NRe2o+TkxPCw8Nx7do19OzZs8lxEVHz4IxbIiIA1tbW0NXVRXR09Av32bBhQ61v5Ldv3w4HBwfx9fz58zFz5kxERUXB2toaVlZWiIyMRGVlJZYvX44BAwZgyJAh2L9/f63+s7Oz8emnn6Jv374YPXo0UlJS5LZfvXoV//73v2FhYQFra2t88cUXePjwobjd1dUVYWFhWLJkCQYOHAgPD48630d1dTUiIyMxZMgQcZbBL7/8Im6XSCS4fPkyNm7cCIlEgg0bNtTq48SJE7CyskJVVRUAIDMzExKJRO5b/MDAQPj5+Ymvjx49CkdHR0ilUjg4OGDbtm1yfTo4OGDjxo348ssvYWlpia+++grA09kHQ4cOhZmZGby8vGoNgLOysuDq6goLCwtYWlrC2dmZt4ERERGRQoSGhkJJSQnffPMNRo0aBSMjI/Ts2RPu7u6Ii4t74XErV67EqFGjYGZmhuHDh2PdunWoqKgQt9c33rl37x48PT3Rv39/mJubw9HRET///PMLz5WQkACJRIJ33nlHbDt8+DAqKiqwdOlS9OzZE46OjnB1dUVMTEyT8tGuXTvo6emha9eumDZtGrS1tXH69Glxe1FREQIDAzFo0CBYWlrCzc0NWVlZ4vacnBzMmDED1tbWsLCwwLhx4+SOf1VBQUH4/PPP0bVr1yb3VVRUhNTUVPj5+WHQoEHo0qUL+vXrh+nTp2P48OHifjExMXBycoK5uTns7e0REhKCkpISAMDZs2cREBCAx48fi7OUa8bgzy+VIJFIsGfPHnh6esLc3BxRUVEAnt4tOHbsWPTt2xfDhw8Xr0FqaGlpwdLSEvHx8U1+z0TUfDjjlogIgLKyMnx9fTFv3jy4ubmhU6dOr9zXmTNn0KlTJ+zatQvp6ekIDAxERkYG+vfvj7i4OBw5cgTBwcGwsbGRO8+KFSuwYMEC9OjRAzExMfD09MRPP/0EHR0dFBUVYdKkSRg/fjwCAgLw5MkTrFq1Cj4+PoiNjRX7+O677+Di4oK9e/e+ML7Y2FjExMQgLCwMvXv3xv79+zFz5kz88MMP6NatG06dOgV3d3fY2dlhypQpaNu2ba0+rKysUFJSgitXrqBv375ISUmBjo6OXLH5v//9L6ZOnQoAuHTpEnx8fDBr1ix89NFHyMjIQGhoKLS1teHs7Cwes23bNnh5eWHWrFkAgPPnzyMwMBC+vr4YMWIEkpKSahWS/fz80Lt3b4SEhEBFRQWZmZkNmnVARERE9Do9evQISUlJmDt3bp3jp/bt27/w2Hbt2mHZsmXQ19fH1atXsXDhQrRr104cS9U33gkLC0NFRQV27dqFtm3b4vr163Wev0ZqaiqkUqlc27lz52BlZSV3t5OtrS1kMhkKCwuhpaWFw4cPIzg4uN4cyGSyOm/3r66uxrFjx1BYWCg3TpszZ45455umpib+85//YNKkSTh69Ci0tbVRWloKe3t7zJ07F+rq6jh48CA8PT3x448/onPnzvXG0hS5ublwdHSsd5/p06fD09MTbdu2Rdu2bZGYmAhzc/MX3jGmpKSEwMBAGBgY4M6dOwgNDcXKlSsREhICCwsLLFiwABEREeKs7Pr+DyMjIzFv3jwEBgZCRUUFqamp8Pf3R1BQEKysrJCTkyPOqK4ZVwNAv379GrV8AxEpHgu3RET/8/7776N3796IiIjA0qVLX7kfbW1tBAUFQVlZGd27d8eWLVtQVlYGT09PAE8HeTKZDGlpaXIDws8//xyjRo0CAISEhCApKQnffvstpk6dil27dsHU1BS+vr7i/kuXLoW9vT1u3rwJIyMjAEC3bt3w5Zdf1hvf1q1bMXXqVPHcX3zxBc6ePYsdO3YgODgYenp6UFFRQdu2baGnp1dnH5qamujduzdSUlLEwu3kyZMRGRmJkpISFBcX4/bt2+jfvz+ApzMMBg8eDC8vLwCAkZERrl+/jq1bt8oVbgcNGoQpU6aIr9evXw87OzvxosXIyAgZGRlISkoS98nNzYWHhweMjY3FHBARERE1t5ycHAiCgO7duzf62JkzZ4o/GxgY4ObNm4iPjxfHQPWNd3JzczFq1Cjx2Qwvm0Wam5tbq3Cbn58PAwMDuTZdXV1xm5aWFhwcHGBmZlZv38/O4gWAVatWYf369SgvL0dlZSW0tbUxfvx4AE8LyBcuXEBycrJY7PT390diYiKOHj2KCRMmoFevXujVq5fYn4+PDxITE3H8+HFMnDix3liaQl9fHwcPHqx3n5rl1VRVVREeHo6FCxdi3759MDU1xYABA/DRRx/JxT558mTxZwMDA/j4+CA4OBghISFQV1eHpqYmlJSUXjj+ftbo0aMxbtw48fWCBQswbdo0jB07FsDT34E5c+Zg5cqVcoVbfX193Lt3ryEpIKIWgoVbIqJn+Pn5YdKkSS9cZqAhevToAWXlv1ai0dXVlVtHSkVFBdra2igoKJA7zsLCQvxZVVUVUqkU2dnZAJ7eHnf27Fm5fWrk5OSIhds+ffrUG1txcTEePHgAS0tLuXZLS0u529Iaon///khJScGUKVOQmpoKX19fJCQkIC0tDYWFhdDX1xcvKrKzs+VuFas5Z2xsLKqqqqCiogIAtS4ibty4gREjRsi1mZubyxVu3d3dERQUhEOHDsHa2hoffPAB3nvvvUa9FyIiIqKmEgThlY89cuQIYmNjcefOHZSWlqKyslLuwWH1jXfc3NwQEhKCU6dOwdraGiNHjpQrGD6vrKwMrVq1anSMGhoacjE1hIeHB5ydnZGXl4cVK1bgs88+g6GhIQDgt99+Q2lpKQYOHFgrvpycHABASUkJIiMjcfLkSeTl5aGqqgplZWXIzc1tdPyNoaqqKsbZEKNGjcLQoUORmpqKc+fOISkpCVu2bBEfggYAp0+fRnR0NLKzs1FcXIyqqio8efIEf/75J9q0adOo+J4fM2dlZSE9PV1cNgFAnf23bt0aZWVljToXESkWC7dERM/o378/bG1tsXr1armZoMDT25ueH5A/u25UDVVV+T+tSkpKdbZVV1c3OK7S0lIMGzZMbs3YGs9+K9/YQV9TDBgwAPv370dWVhbU1NRgbGyMAQMGICUlBUVFRRgwYECj+3yV+GfPno3Ro0fj559/xi+//IKIiAisXbsW77//fqP7IiIiInpVhoaGUFJSEr94b6iMjAz4+flh9uzZsLW1haamJuLj4+XWl61vvDN+/HjY2tri5MmT+PXXX7F582b4+/vD1dW1zvPVLMP1LF1dXeTn58u11byumXn7Kksl6OjowNDQEIaGhli/fj2cnJwglUrRo0cPlJSUQE9PDzt37qzVj6amJgBg+fLlOH36NPz9/fHee++hdevW8Pb2llv/901ozFIJNVq1agUbGxvY2NjAy8sLgYGB2LBhA5ydnXH37l1Mnz4dLi4umDt3LrS0tJCWlobAwEBUVFQ0egz8/DIKpaWlmD17NkaOHFlr32eL9I8ePXrpw86IqGVh4ZaI6Dnz5s3DmDFjxFmsNTp06ID8/HwIggAlJSUATx/K9bqcO3dOXFqgsrISly9fxueffw7g6Uzao0ePokuXLrWKwI2hoaEBfX19pKenyxVW09PT0a9fv0b1VbPO7fbt28W4Bw4ciM2bN6OwsFBuyYPu3bsjPT1d7vj09HR069ZNnG1bF2NjY1y4cEGu7fz587X2MzIygpGRESZPngxfX1/s37+fhVsiIiJqVtra2rC1tcXu3bvh6upaq7hWVFRU5zq3GRkZ6Ny5M2bMmCG21TWjtL7xzrvvvgsXFxe4uLhg9erViIuLe2Hh1tTUFNevX5drMzc3Fx+IVrMG7enTp2FkZCQuCfAqSyU8691338VHH32E1atXY9OmTejTpw/y8/OhoqJSa5mGGhkZGRg7dqz4PktKSprlVv/GLJXwIj169EBiYiIA4PLlyxAEAfPnzxfvzEtISJDbX01NTXzwb2OZmpri5s2bL50lfO3aNfTu3fuVzkFEiqH88l2IiN4uEokETk5Otb79HzhwIB4+fAiZTIacnBzs3r1b7pb9ptqzZw+OHTuGGzduICwsDIWFheLaVZ999hkKCwvh6+uLCxcuICcnB0lJSQgICGj0AM/DwwMymQxHjhxBdnY2Vq1ahaysLLi5uTWqHy0tLUgkEnz//fdiEdjKygpXrlzBrVu3xGIuAEyZMgXJycnYuHEjbt68ie+++w67d++WK+7WxdXVFUlJSdi6dStu3bqFXbt2yeW8rKwMYWFhOHv2LO7du4e0tDRcvHhRXP+NiIiIqDkFBwejuroa48ePx9GjR3Hr1i3cuHEDsbGxmDBhQp3HGBoa4vfff0d8fDxycnIQGxsrFvyAl493lixZgqSkJNy5cweXL1/G2bNn6x0L2dra4ty5c3JjSCcnJ6ipqSEwMBDXrl0Tl25wd3cX99HQ0BBnz77oX+vWrevNj5ubG06cOIGLFy/C2toa5ubm8PLywqlTp3D37l2kp6dj7dq1uHjxopibY8eOITMzE1lZWZg3b16j7lp7kdu3byMzMxN5eXkoKytDZmYmMjMzUV5eDuCvpRLq+6etrQ0A+OOPP+Dm5oZDhw4hKysLd+7cQUJCArZs2SIuFWZoaIiKigrs3LkTd+7cwcGDB7Fv3z65mLp06YLS0lIkJyfj4cOH+PPPPxv8fry8vHDo0CFERkbi2rVruHHjBuLj47F27Vq5/dLS0mBjY9OEzBFRc+OMWyKiOnh7e+PIkSNybcbGxggODkZ0dDQ2bdqEkSNHYsqUKYiLi3st55w3bx42b96MzMxMGBoaYtOmTeKtTO+88w727t2LVatWwcPDA+Xl5ejcuTPs7Ozk1tNtCDc3NxQXFyM8PBwPHz6EsbExvv7661d6qFf//v2RmZkpFm61tbVhbGyMgoICuQdz9OnTB+vWrUNERAQ2bdoEPT09eHt711qO4nnm5uZYtGgRNmzYgIiICAwePBgzZszA119/DQBQVlbGo0eP4O/vj/z8fOjo6GDkyJHw9vZu9HshIiIiaqquXbviwIEDiIqKwvLly/HgwQN06NABffr0QUhISJ3HDB8+HJMmTUJYWBjKy8sxdOhQzJgxA5GRkQBePt6prq5GWFgY7t+/Dw0NDdjZ2SEgIOCFMQ4ZMgQqKio4ffo07OzsADxdmmDr1q0ICwuDs7MzdHR0MHPmzBcWm19Vjx49YGNjg4iICMhkMmzevBnr1q1DQEAA/vjjD+jq6sLKykpcnmH+/PlYsGABPv30U+jo6GDq1KkoKSmp9xzz58/HvXv36lyCoUZQUBBSUlLE12PGjAEA/PTTTy+c/fsi7dq1g5mZGXbs2IGcnBxUVlaiU6dOGD9+vLiUQq9evRAQEACZTIY1a9bAysoKvr6+8Pf3F/uxtLTEp59+Ch8fHzx69AizZs3C7NmzGxSDnZ0doqKisHHjRshkMqiqqqJ79+7ig+CAp7OXHz9+jA8++KBR74+IFEtJaMoK6kRERERERET0/8ru3btx/PhxbN26VdGhvHYTJ07EwIEDG1z0fFv4+PigV69ecuvyElHLxxm3RERERERERG+RCRMmoKioCMXFxdDQ0FB0OK/N48ePkZOTg+joaEWH0qKUl5fDxMQEkydPVnQoRNRInHFLRERERERERERE1MLw4WRERERERERERERELQwLt0REREREREREREQtDAu3RERERERERERERC0MC7dERERERERERERELQwLt0REREREREREREQtDAu3RERERERERERERC0MC7dERERERERERERELQwLt0REREREREREREQtDAu3RERERERERERERC3M/wEp2YbLOATvAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average headline length:\n",
      "  Real: 9.82 words\n",
      "  Satire: 10.31 words\n"
     ]
    }
   ],
   "source": [
    "# Headline length distribution\n",
    "df['headline_length'] = df['headline'].str.split().str.len()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Length distribution by class\n",
    "df[df['is_sarcastic'] == 0]['headline_length'].hist(bins=30, alpha=0.7, label='Real', ax=ax[0])\n",
    "df[df['is_sarcastic'] == 1]['headline_length'].hist(bins=30, alpha=0.7, label='Satire', ax=ax[0])\n",
    "ax[0].set_xlabel('Number of words')\n",
    "ax[0].set_ylabel('Frequency')\n",
    "ax[0].set_title('Headline Length Distribution')\n",
    "ax[0].legend()\n",
    "\n",
    "# Box plot\n",
    "df.boxplot(column='headline_length', by='is_sarcastic', ax=ax[1])\n",
    "ax[1].set_xlabel('Class (0=Real, 1=Satire)')\n",
    "ax[1].set_ylabel('Number of words')\n",
    "ax[1].set_title('Headline Length by Class')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average headline length:\")\n",
    "print(f\"  Real: {df[df['is_sarcastic'] == 0]['headline_length'].mean():.2f} words\")\n",
    "print(f\"  Satire: {df[df['is_sarcastic'] == 1]['headline_length'].mean():.2f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 22,895 samples\n",
      "Test set: 5,724 samples\n",
      "\n",
      "Train class distribution:\n",
      "is_sarcastic\n",
      "0    11990\n",
      "1    10905\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "is_sarcastic\n",
      "0    2995\n",
      "1    2729\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"Training set: {len(train_df):,} samples\")\n",
    "print(f\"Test set: {len(test_df):,} samples\")\n",
    "print(f\"\\nTrain class distribution:\")\n",
    "print(train_df['is_sarcastic'].value_counts())\n",
    "print(f\"\\nTest class distribution:\")\n",
    "print(test_df['is_sarcastic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method 1: Naive Baseline\n",
    "\n",
    "A simple rule-based approach using keyword scoring:\n",
    "- Intensifiers (+1.5): \"absolutely\", \"totally\", \"perfect\", etc.\n",
    "- Satirical triggers (+2.0): \"area man\", \"nation\", \"study finds\", etc.\n",
    "- Punctuation (+0.5): !, ?, or quotes\n",
    "\n",
    "Headlines scoring ≥ 1.5 are classified as satire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 2.0 | area man passionate defender of what he imagines constitution to be\n",
      "Score: 0.0 | trump announces new immigration policy\n"
     ]
    }
   ],
   "source": [
    "def get_sarcasm_score(headline):\n",
    "    \"\"\"Calculate sarcasm score based on keyword rules.\"\"\"\n",
    "    text = headline.lower()\n",
    "    score = 0\n",
    "    \n",
    "    intensifiers = [\n",
    "        'absolutely', 'totally', 'clearly', 'literally', 'completely', \n",
    "        'miracle', 'amazing', 'perfect', 'best', 'worst', 'incredible',\n",
    "        'shocking', 'breaking', 'finally'\n",
    "    ]\n",
    "    for word in intensifiers:\n",
    "        if word in text.split():\n",
    "            score += 1.5\n",
    "    \n",
    "    sarcasm_triggers = [\n",
    "        'area man', 'area woman', 'local man', 'local woman', \n",
    "        'nation', 'study finds', 'report:', 'god', 'scientists'\n",
    "    ]\n",
    "    for trigger in sarcasm_triggers:\n",
    "        if trigger in text:\n",
    "            score += 2.0\n",
    "    \n",
    "    if '!' in text or '?' in text:\n",
    "        score += 0.5\n",
    "    if '\"' in text:\n",
    "        score += 0.5\n",
    "        \n",
    "    return score\n",
    "\n",
    "def predict_baseline(headlines, threshold=1.5):\n",
    "    \"\"\"Predict using naive baseline.\"\"\"\n",
    "    predictions = []\n",
    "    for headline in headlines:\n",
    "        score = get_sarcasm_score(headline)\n",
    "        predictions.append(1 if score >= threshold else 0)\n",
    "    return predictions\n",
    "\n",
    "# Test the scoring function\n",
    "test_headlines = [\n",
    "    \"area man passionate defender of what he imagines constitution to be\",\n",
    "    \"trump announces new immigration policy\"\n",
    "]\n",
    "for headline in test_headlines:\n",
    "    score = get_sarcasm_score(headline)\n",
    "    print(f\"Score: {score:.1f} | {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Naive Baseline...\n",
      "\n",
      "Naive Baseline Results:\n",
      "  Accuracy:  0.5646 (56.46%)\n",
      "  F1 Score:  0.2421\n",
      "  Precision: 0.7120\n",
      "  Recall:    0.1458\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.55      0.95      0.69      2995\n",
      "      Satire       0.71      0.15      0.24      2729\n",
      "\n",
      "    accuracy                           0.56      5724\n",
      "   macro avg       0.63      0.55      0.47      5724\n",
      "weighted avg       0.63      0.56      0.48      5724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run naive baseline\n",
    "print(\"Running Naive Baseline...\")\n",
    "y_pred_naive = predict_baseline(test_df['headline'].values, threshold=1.5)\n",
    "y_true = test_df['is_sarcastic'].values\n",
    "\n",
    "# Calculate metrics\n",
    "naive_results = {\n",
    "    'accuracy': accuracy_score(y_true, y_pred_naive),\n",
    "    'f1': f1_score(y_true, y_pred_naive),\n",
    "    'precision': precision_score(y_true, y_pred_naive),\n",
    "    'recall': recall_score(y_true, y_pred_naive)\n",
    "}\n",
    "\n",
    "print(f\"\\nNaive Baseline Results:\")\n",
    "print(f\"  Accuracy:  {naive_results['accuracy']:.4f} ({naive_results['accuracy']*100:.2f}%)\")\n",
    "print(f\"  F1 Score:  {naive_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {naive_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {naive_results['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_naive, target_names=['Real', 'Satire']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method 2: Embedding + Centroid\n",
    "\n",
    "Uses Sentence-BERT to encode headlines into 768-dimensional vectors.\n",
    "Classifies based on cosine similarity to class centroids (mean vectors).\n",
    "No training required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence-BERT model: all-mpnet-base-v2\n",
      "Using device: cuda\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load Sentence-BERT model\n",
    "print(f\"Loading Sentence-BERT model: {EMBEDDING_MODEL}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "sbert_model = SentenceTransformer(EMBEDDING_MODEL, device=device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding training set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ae8b7a39ac4031a5798b3bd8f277c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training embeddings shape: (22895, 768)\n",
      "Satire centroid shape: (1, 768)\n",
      "Real centroid shape: (1, 768)\n"
     ]
    }
   ],
   "source": [
    "# Encode training set and compute centroids\n",
    "print(\"Encoding training set...\")\n",
    "X_train = sbert_model.encode(train_df['headline'].tolist(), show_progress_bar=True)\n",
    "y_train = train_df['is_sarcastic'].values\n",
    "\n",
    "print(f\"Training embeddings shape: {X_train.shape}\")\n",
    "\n",
    "# Compute class centroids\n",
    "centroid_satire = np.mean(X_train[y_train == 1], axis=0).reshape(1, -1)\n",
    "centroid_real = np.mean(X_train[y_train == 0], axis=0).reshape(1, -1)\n",
    "\n",
    "print(f\"Satire centroid shape: {centroid_satire.shape}\")\n",
    "print(f\"Real centroid shape: {centroid_real.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f08ec1389a4521bcebeb25c28173b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape: (5724, 768)\n"
     ]
    }
   ],
   "source": [
    "# Encode test set\n",
    "print(\"Encoding test set...\")\n",
    "X_test = sbert_model.encode(test_df['headline'].tolist(), show_progress_bar=True)\n",
    "print(f\"Test embeddings shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying test samples...\n",
      "\n",
      "Embedding + Centroid Results:\n",
      "  Accuracy:  0.7472 (74.72%)\n",
      "  F1 Score:  0.7331\n",
      "  Precision: 0.7381\n",
      "  Recall:    0.7281\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.76      0.76      0.76      2995\n",
      "      Satire       0.74      0.73      0.73      2729\n",
      "\n",
      "    accuracy                           0.75      5724\n",
      "   macro avg       0.75      0.75      0.75      5724\n",
      "weighted avg       0.75      0.75      0.75      5724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classify using centroid distance\n",
    "print(\"Classifying test samples...\")\n",
    "y_pred_centroid = []\n",
    "for vec in X_test:\n",
    "    vec = vec.reshape(1, -1)\n",
    "    sim_satire = cosine_similarity(vec, centroid_satire)[0][0]\n",
    "    sim_real = cosine_similarity(vec, centroid_real)[0][0]\n",
    "    y_pred_centroid.append(1 if sim_satire > sim_real else 0)\n",
    "\n",
    "# Calculate metrics\n",
    "centroid_results = {\n",
    "    'accuracy': accuracy_score(y_true, y_pred_centroid),\n",
    "    'f1': f1_score(y_true, y_pred_centroid),\n",
    "    'precision': precision_score(y_true, y_pred_centroid),\n",
    "    'recall': recall_score(y_true, y_pred_centroid)\n",
    "}\n",
    "\n",
    "print(f\"\\nEmbedding + Centroid Results:\")\n",
    "print(f\"  Accuracy:  {centroid_results['accuracy']:.4f} ({centroid_results['accuracy']*100:.2f}%)\")\n",
    "print(f\"  F1 Score:  {centroid_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {centroid_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {centroid_results['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_centroid, target_names=['Real', 'Satire']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Method 3: Embedding + Logistic Regression\n",
    "\n",
    "Uses the same Sentence-BERT embeddings but trains a Logistic Regression classifier\n",
    "to learn a task-specific decision boundary in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression classifier...\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression classifier...\")\n",
    "lr_clf = LogisticRegression(random_state=RANDOM_SEED, max_iter=1000, solver='lbfgs', verbose=0)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set...\n",
      "\n",
      "Embedding + LR Results:\n",
      "  Accuracy:  0.8471 (84.71%)\n",
      "  F1 Score:  0.8382\n",
      "  Precision: 0.8462\n",
      "  Recall:    0.8303\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.85      0.86      0.86      2995\n",
      "      Satire       0.85      0.83      0.84      2729\n",
      "\n",
      "    accuracy                           0.85      5724\n",
      "   macro avg       0.85      0.85      0.85      5724\n",
      "weighted avg       0.85      0.85      0.85      5724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "lr_results = {\n",
    "    'accuracy': accuracy_score(y_true, y_pred_lr),\n",
    "    'f1': f1_score(y_true, y_pred_lr),\n",
    "    'precision': precision_score(y_true, y_pred_lr),\n",
    "    'recall': recall_score(y_true, y_pred_lr)\n",
    "}\n",
    "\n",
    "print(f\"\\nEmbedding + LR Results:\")\n",
    "print(f\"  Accuracy:  {lr_results['accuracy']:.4f} ({lr_results['accuracy']*100:.2f}%)\")\n",
    "print(f\"  F1 Score:  {lr_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {lr_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {lr_results['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_lr, target_names=['Real', 'Satire']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4 & 5 Setup: LLM with vLLM or Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen2.5-32B-Instruct from /root/model/Qwen2.5-32B-Instruct-AWQ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "/usr/local/lib/python3.10/dist-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae0fb4fc5fd48bd8160e73bf2001593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded (GPU memory: 18.48 GB)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "# Load LLM model\n",
    "LOCAL_MODEL_PATH = Path.home() / \"model\" / \"Qwen2.5-32B-Instruct-AWQ\"\n",
    "\n",
    "print(f\"Loading Qwen2.5-32B-Instruct from {LOCAL_MODEL_PATH}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(LOCAL_MODEL_PATH))\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    str(LOCAL_MODEL_PATH),\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "print(f\"✓ Model loaded (GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Method 4: LLM Zero-shot\n",
    "\n",
    "Zero-shot classification using Qwen2.5-32B-Instruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test output: Classification: Satire\n",
      "\n",
      "Explanation: The headline uses\n"
     ]
    }
   ],
   "source": [
    "def query_zeroshot(headline):\n",
    "    \"\"\"Query LLM with zero-shot prompt.\"\"\"\n",
    "    system_prompt = \"\"\"You are an expert linguist identifying satire. \n",
    "Classify the given news headline into 'Satire' (The Onion) or 'Real' (HuffPost).\n",
    "DEFINITION OF SATIRE (The Onion):\n",
    "1. Absurd situations that violate physical laws or logic.\n",
    "2. Mundane, trivial everyday behaviors presented as 'breaking news'.\n",
    "3. Specific satirical phrases: 'Area Man', 'Nation', 'Study finds'.\n",
    "DEFINITION OF REAL NEWS:\n",
    "1. Factual reporting about specific politicians, celebrities, or companies.\n",
    "2. Opinions or commentaries on actual political/social events.\n",
    "3. Even if the event sounds strange, if it involves real entities, it is likely Real.\"\"\"\n",
    "    \n",
    "    user_prompt = f'Headline: \"{headline}\"\\n\\nClassify as \\'Satire\\' or \\'Real\\'.'\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\").to(llm_model.device)\n",
    "    \n",
    "    outputs = llm_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=10,\n",
    "        do_sample=False  \n",
    "    )\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return result.strip()\n",
    "\n",
    "# Test the function\n",
    "test_output = query_zeroshot(\"area man passionate defender of what he imagines constitution to be\")\n",
    "print(f\"Test output: {test_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLM Zero-shot on 5724 samples...\n",
      "This may take a while depending on GPU speed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896c504066f541d18e30a7cb84d62a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Zero-shot Results:\n",
      "  Accuracy:  0.8187 (81.87%)\n",
      "  F1 Score:  0.7995\n",
      "  Precision: 0.8455\n",
      "  Recall:    0.7582\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.80      0.87      0.83      2995\n",
      "      Satire       0.85      0.76      0.80      2729\n",
      "\n",
      "    accuracy                           0.82      5724\n",
      "   macro avg       0.82      0.82      0.82      5724\n",
      "weighted avg       0.82      0.82      0.82      5724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM zero-shot on test set\n",
    "print(f\"Running LLM Zero-shot on {len(test_df)} samples...\")\n",
    "print(\"This may take a while depending on GPU speed.\\n\")\n",
    "\n",
    "y_pred_llm_zero = []\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    output = query_zeroshot(row['headline'])\n",
    "    y_pred_llm_zero.append(1 if \"satire\" in output.lower() else 0)\n",
    "\n",
    "# Calculate metrics\n",
    "llm_zero_results = {\n",
    "    'accuracy': accuracy_score(y_true, y_pred_llm_zero),\n",
    "    'f1': f1_score(y_true, y_pred_llm_zero),\n",
    "    'precision': precision_score(y_true, y_pred_llm_zero),\n",
    "    'recall': recall_score(y_true, y_pred_llm_zero)\n",
    "}\n",
    "\n",
    "print(f\"\\nLLM Zero-shot Results:\")\n",
    "print(f\"  Accuracy:  {llm_zero_results['accuracy']:.4f} ({llm_zero_results['accuracy']*100:.2f}%)\")\n",
    "print(f\"  F1 Score:  {llm_zero_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {llm_zero_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {llm_zero_results['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_llm_zero, target_names=['Real', 'Satire']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Method 5: LLM Few-shot\n",
    "\n",
    "Same LLM but with 8 example headlines (4 satire + 4 real) in the prompt.\n",
    "Shows the model what kinds of headlines belong to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test output: Classification: Satire\n",
      "\n",
      "Explanation: The phrase \"\n"
     ]
    }
   ],
   "source": [
    "def query_fewshot(headline):\n",
    "    \"\"\"Query LLM with few-shot prompt.\"\"\"\n",
    "    system_prompt = \"\"\"You distinguish The Onion satire from real news.\n",
    "SATIRICAL (The Onion):\n",
    "- \"Area man/woman\" + mundane behavior as news\n",
    "- \"Nation\" as a character doing absurd things\n",
    "- \"Study finds\" + obvious common sense\n",
    "- \"Report:\" + self-evident statements\n",
    "- \"God\" making mundane announcements\n",
    "- Ordinary events as breaking news\n",
    "- Exaggerated absolute language\n",
    "- Generic people in mundane situations\n",
    "- Real politicians/Celebrities doing oddly mundane or out-of-character things\n",
    "- Companies announcing products that already exist or are useless\n",
    "REAL NEWS (even if unusual):\n",
    "- Named politicians, celebrities, companies\n",
    "- Actual products and marketing campaigns\n",
    "- Real sports events and commentary\n",
    "- Legal cases with specific parties\n",
    "- Entertainment industry announcements\n",
    "- Opinion pieces on current events\n",
    "- Weird pop-culture news or bizarre viral trends\n",
    "CRITICAL: Many real news articles are weird, provocative, or satirical in TONE but describe REAL events/people/products. If it mentions specific names or real entities, it is usually REAL, UNLESS the action they are doing is functionally useless or weirdly mundane.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"EXAMPLES:\n",
    "\n",
    "SATIRICAL:\n",
    "\"area man passionate defender of what he imagines constitution to be\"\n",
    "\"nation celebrates full week without mass shooting\"\n",
    "\"ford develops new suv that runs purely on gasoline\"\n",
    "(Reason: Real company (Ford) but announcing a mundane product feature as innovation.)\n",
    "\"eric holder loads ipod with ap phone conversations for morning commute\"\n",
    "(Reason: Real politician (Eric Holder) doing a bizarrely mundane/specific action.)\n",
    "\n",
    "REAL (even though they sound satirical):\n",
    "\"the gop's stockholm syndrome\"\n",
    "(Reason: Political opinion/metaphor.)\n",
    "\"riot grill for meat-loving feminists\"\n",
    "(Reason: Real restaurant/marketing.)\n",
    "\"jon snow has been battling white walkers while wearing an ikea rug\"\n",
    "(Reason: Real entertainment news about a TV show costume.)\n",
    "\"10-pound doughnut at hotel\"\n",
    "(Reason: Real product announcement.)\n",
    "\n",
    "Classify: \"{headline}\"\n",
    "\n",
    "Answer: Satire or Real\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\").to(llm_model.device)\n",
    "    \n",
    "    outputs = llm_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=10,\n",
    "        do_sample=False  \n",
    "    )\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return result.strip()\n",
    "\n",
    "# Test the function\n",
    "test_output = query_fewshot(\"area man passionate defender of what he imagines constitution to be\")\n",
    "print(f\"Test output: {test_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLM Few-shot on 5724 samples...\n",
      "This may take a while depending on GPU speed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807be3308db14ad098556251869960e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Few-shot Results:\n",
      "  Accuracy:  0.8295 (82.95%)\n",
      "  F1 Score:  0.8402\n",
      "  Precision: 0.7595\n",
      "  Recall:    0.9399\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.93      0.73      0.82      2995\n",
      "      Satire       0.76      0.94      0.84      2729\n",
      "\n",
      "    accuracy                           0.83      5724\n",
      "   macro avg       0.84      0.83      0.83      5724\n",
      "weighted avg       0.85      0.83      0.83      5724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run LLM few-shot on test set\n",
    "print(f\"Running LLM Few-shot on {len(test_df)} samples...\")\n",
    "print(\"This may take a while depending on GPU speed.\\n\")\n",
    "\n",
    "y_pred_llm_few = []\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    output = query_fewshot(row['headline'])\n",
    "    y_pred_llm_few.append(1 if \"satire\" in output.lower() else 0)\n",
    "\n",
    "# Calculate metrics\n",
    "llm_few_results = {\n",
    "    'accuracy': accuracy_score(y_true, y_pred_llm_few),\n",
    "    'f1': f1_score(y_true, y_pred_llm_few),\n",
    "    'precision': precision_score(y_true, y_pred_llm_few),\n",
    "    'recall': recall_score(y_true, y_pred_llm_few)\n",
    "}\n",
    "\n",
    "print(f\"\\nLLM Few-shot Results:\")\n",
    "print(f\"  Accuracy:  {llm_few_results['accuracy']:.4f} ({llm_few_results['accuracy']*100:.2f}%)\")\n",
    "print(f\"  F1 Score:  {llm_few_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {llm_few_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {llm_few_results['recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_llm_few, target_names=['Real', 'Satire']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PERFORMANCE COMPARISON (Table 1 from report)\n",
      "======================================================================\n",
      "                      accuracy        f1  precision    recall\n",
      "Naive Baseline        0.564640  0.242092   0.711986  0.145841\n",
      "Embedding + Centroid  0.747205  0.733075   0.738113  0.728106\n",
      "Embedding + LR        0.847135  0.838173   0.846154  0.830341\n",
      "LLM Zero-shot         0.818658  0.799459   0.845525  0.758153\n",
      "LLM Few-shot          0.829490  0.840157   0.759550  0.939905\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Compile all results\n",
    "all_results = {\n",
    "    'Naive Baseline': naive_results,\n",
    "    'Embedding + Centroid': centroid_results,\n",
    "    'Embedding + LR': lr_results,\n",
    "    'LLM Zero-shot': llm_zero_results,\n",
    "    'LLM Few-shot': llm_few_results\n",
    "}\n",
    "\n",
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(all_results).T\n",
    "results_df = results_df[['accuracy', 'f1', 'precision', 'recall']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE COMPARISON (Table 1 from report)\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string())\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Qualitative Analysis\n",
    "\n",
    "Examining cases where methods agree or disagree to understand their strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 5724\n"
     ]
    }
   ],
   "source": [
    "# Create analysis dataframe\n",
    "analysis_df = test_df.copy()\n",
    "analysis_df['true_label'] = y_true\n",
    "analysis_df['naive'] = y_pred_naive\n",
    "analysis_df['embedding_lr'] = y_pred_lr\n",
    "analysis_df['llm_few'] = y_pred_llm_few\n",
    "\n",
    "analysis_df['naive_correct'] = (analysis_df['naive'] == analysis_df['true_label'])\n",
    "analysis_df['embedding_correct'] = (analysis_df['embedding_lr'] == analysis_df['true_label'])\n",
    "analysis_df['llm_correct'] = (analysis_df['llm_few'] == analysis_df['true_label'])\n",
    "\n",
    "print(f\"Total test samples: {len(analysis_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREDICTION PATTERN DISTRIBUTION (Table 2 from report)\n",
      "======================================================================\n",
      "Pattern                             Count      Percentage\n",
      "----------------------------------------------------------------------\n",
      "All Correct (✓✓✓)                    2178           38.1%\n",
      "Embedding+LLM Correct (✗✓✓)          1919           33.5%\n",
      "Naive+Embedding Correct (✓✓✗)         620           10.8%\n",
      "Naive+LLM Correct (✓✗✓)               292            5.1%\n",
      "Only LLM Correct (✗✗✓)                359            6.3%\n",
      "Only Naive Correct (✓✗✗)              142            2.5%\n",
      "Only Embedding Correct (✗✓✗)          132            2.3%\n",
      "All Wrong (✗✗✗)                        82            1.4%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Count agreement patterns\n",
    "def categorize_case(row):\n",
    "    n = row['naive_correct']\n",
    "    e = row['embedding_correct']\n",
    "    l = row['llm_correct']\n",
    "    return (n, e, l)\n",
    "\n",
    "analysis_df['case_type'] = analysis_df.apply(categorize_case, axis=1)\n",
    "\n",
    "case_counts = analysis_df['case_type'].value_counts().sort_index(ascending=False)\n",
    "case_percentages = (case_counts / len(analysis_df) * 100).round(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTION PATTERN DISTRIBUTION (Table 2 from report)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Pattern':<30} {'Count':>10} {'Percentage':>15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "pattern_names = {\n",
    "    (True, True, True): \"All Correct (✓✓✓)\",\n",
    "    (False, True, True): \"Embedding+LLM Correct (✗✓✓)\",\n",
    "    (True, True, False): \"Naive+Embedding Correct (✓✓✗)\",\n",
    "    (False, False, True): \"Only LLM Correct (✗✗✓)\",\n",
    "    (True, False, True): \"Naive+LLM Correct (✓✗✓)\",\n",
    "    (True, False, False): \"Only Naive Correct (✓✗✗)\",\n",
    "    (False, True, False): \"Only Embedding Correct (✗✓✗)\",\n",
    "    (False, False, False): \"All Wrong (✗✗✗)\"\n",
    "}\n",
    "\n",
    "for pattern in sorted(pattern_names.keys(), key=lambda x: sum(x), reverse=True):\n",
    "    if pattern in case_counts:\n",
    "        count = case_counts[pattern]\n",
    "        pct = case_percentages[pattern]\n",
    "        print(f\"{pattern_names[pattern]:<30} {count:>10} {pct:>14.1f}%\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example cases\n",
    "def show_case_examples(case_type, n_examples=3):\n",
    "    \"\"\"Display examples of a specific case type.\"\"\"\n",
    "    cases = analysis_df[analysis_df['case_type'] == case_type]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Case: {pattern_names[case_type]}\")\n",
    "    print(f\"Total: {len(cases)} samples\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    for idx, (_, row) in enumerate(cases.head(n_examples).iterrows(), 1):\n",
    "        print(f\"\\nExample {idx}:\")\n",
    "        print(f\"  Headline: \\\"{row['headline']}\\\"\")\n",
    "        print(f\"  True Label: {'Satire' if row['true_label'] == 1 else 'Real'}\")\n",
    "        print(f\"  Predictions:\")\n",
    "        print(f\"    Naive:     {'Satire' if row['naive'] == 1 else 'Real':10s} {'✓' if row['naive_correct'] else '✗'}\")\n",
    "        print(f\"    Embedding: {'Satire' if row['embedding_lr'] == 1 else 'Real':10s} {'✓' if row['embedding_correct'] else '✗'}\")\n",
    "        print(f\"    LLM:       {'Satire' if row['llm_few'] == 1 else 'Real':10s} {'✓' if row['llm_correct'] else '✗'}\")\n",
    "        print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Case: All Correct (✓✓✓)\n",
      "Total: 2178 samples\n",
      "======================================================================\n",
      "\n",
      "Example 1:\n",
      "  Headline: \"states slow to shut down weak teacher education programs\"\n",
      "  True Label: Real\n",
      "  Predictions:\n",
      "    Naive:     Real       ✓\n",
      "    Embedding: Real       ✓\n",
      "    LLM:       Real       ✓\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "  Headline: \"report: majority of instances of people getting lives back on track occur immediately after visit to buffalo wild wings\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Satire     ✓\n",
      "    Embedding: Satire     ✓\n",
      "    LLM:       Satire     ✓\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "  Headline: \"the gop's stockholm syndrome\"\n",
      "  True Label: Real\n",
      "  Predictions:\n",
      "    Naive:     Real       ✓\n",
      "    Embedding: Real       ✓\n",
      "    LLM:       Real       ✓\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Case 1: All Correct (37.8%)\n",
    "show_case_examples((True, True, True), n_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Case: Embedding+LLM Correct (✗✓✓)\n",
      "Total: 1919 samples\n",
      "======================================================================\n",
      "\n",
      "Example 1:\n",
      "  Headline: \"drone places fresh kill on steps of white house\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Satire     ✓\n",
      "    LLM:       Satire     ✓\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "  Headline: \"sole remaining lung filled with rich, satisfying flavor\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Satire     ✓\n",
      "    LLM:       Satire     ✓\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "  Headline: \"new extended paternity leave offers dads more time to lose colleagues' respect\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Satire     ✓\n",
      "    LLM:       Satire     ✓\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Case 2: Semantic Understanding Required (33.6%)\n",
    "# Naive fails, Embedding and LLM succeed\n",
    "show_case_examples((False, True, True), n_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Case: Only LLM Correct (✗✗✓)\n",
      "Total: 359 samples\n",
      "======================================================================\n",
      "\n",
      "Example 1:\n",
      "  Headline: \"brad pitt goes completely gray for new movie\"\n",
      "  True Label: Real\n",
      "  Predictions:\n",
      "    Naive:     Satire     ✗\n",
      "    Embedding: Satire     ✗\n",
      "    LLM:       Real       ✓\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "  Headline: \"'just take it slow, and you'll be fine,' drunk driver assures self while speeding away in stolen police car\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Real       ✗\n",
      "    LLM:       Satire     ✓\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "  Headline: \"airline part of something called 'star alliance'\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Real       ✗\n",
      "    LLM:       Satire     ✓\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Case 3: Complex Reasoning Required (6.3%)\n",
    "# Naive and Embedding fail, only LLM succeeds\n",
    "show_case_examples((False, False, True), n_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Case: All Wrong (✗✗✗)\n",
      "Total: 82 samples\n",
      "======================================================================\n",
      "\n",
      "Example 1:\n",
      "  Headline: \"sean spicer finally calls it quits after 6 months of humiliations\"\n",
      "  True Label: Real\n",
      "  Predictions:\n",
      "    Naive:     Satire     ✗\n",
      "    Embedding: Satire     ✗\n",
      "    LLM:       Satire     ✗\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "  Headline: \"trump postpones grand opening of trump tower moscow until fuss over bombshell report dies down\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Real       ✗\n",
      "    LLM:       Real       ✗\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "  Headline: \"confused marines capture al-jazeera leader\"\n",
      "  True Label: Satire\n",
      "  Predictions:\n",
      "    Naive:     Real       ✗\n",
      "    Embedding: Real       ✗\n",
      "    LLM:       Real       ✗\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Case 4: Ambiguous Reality (1.4%)\n",
    "# All methods fail\n",
    "show_case_examples((False, False, False), n_examples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Inference Time Measurement\n",
    "\n",
    "Measure average inference time per sample for efficiency comparison.\n",
    "Uses 11 samples: 1 warmup + 10 measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 11 samples for timing (1 warmup + 10 measured)\n"
     ]
    }
   ],
   "source": [
    "# Select test samples for timing\n",
    "timing_samples = test_df.head(11)\n",
    "print(f\"Using {len(timing_samples)} samples for timing (1 warmup + 10 measured)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(predict_fn, samples, warmup=True):\n",
    "    \"\"\"Measure inference time per sample.\"\"\"\n",
    "    times = []\n",
    "    \n",
    "    for idx, (_, row) in enumerate(samples.iterrows(), 1):\n",
    "        start = time.time()\n",
    "        _ = predict_fn(row['headline'])\n",
    "        elapsed = (time.time() - start) * 1000  # Convert to ms\n",
    "        \n",
    "        # Skip first sample (warmup)\n",
    "        if warmup and idx == 1:\n",
    "            print(f\"  Sample {idx}: {elapsed:.4f} ms (warmup - excluded)\")\n",
    "            continue\n",
    "        \n",
    "        times.append(elapsed)\n",
    "        if idx <= 3 or not warmup:\n",
    "            print(f\"  Sample {idx if not warmup else idx-1}: {elapsed:.4f} ms\")\n",
    "    \n",
    "    return times\n",
    "\n",
    "timing_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring Naive Baseline...\n",
      "  Sample 1: 0.0670 ms (warmup - excluded)\n",
      "  Sample 1: 0.0315 ms\n",
      "  Sample 2: 0.0432 ms\n",
      "Average: 0.0295 ms\n",
      "Std Dev: 0.0062 ms\n"
     ]
    }
   ],
   "source": [
    "# Measure Naive Baseline\n",
    "print(\"Measuring Naive Baseline...\")\n",
    "naive_times = measure_time(\n",
    "    lambda h: predict_baseline([h])[0],\n",
    "    timing_samples\n",
    ")\n",
    "timing_results['Naive Baseline'] = {\n",
    "    'avg': np.mean(naive_times),\n",
    "    'std': np.std(naive_times),\n",
    "    'times': naive_times\n",
    "}\n",
    "print(f\"Average: {timing_results['Naive Baseline']['avg']:.4f} ms\")\n",
    "print(f\"Std Dev: {timing_results['Naive Baseline']['std']:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring Embedding + Centroid...\n",
      "  Sample 1: 39.5281 ms (warmup - excluded)\n",
      "  Sample 1: 10.3984 ms\n",
      "  Sample 2: 9.8536 ms\n",
      "Average: 10.3826 ms\n",
      "Std Dev: 2.0166 ms\n"
     ]
    }
   ],
   "source": [
    "# Measure Embedding + Centroid\n",
    "print(\"\\nMeasuring Embedding + Centroid...\")\n",
    "\n",
    "def predict_centroid_single(headline):\n",
    "    vec = sbert_model.encode([headline], show_progress_bar=False)[0].reshape(1, -1)\n",
    "    sim_satire = cosine_similarity(vec, centroid_satire)[0][0]\n",
    "    sim_real = cosine_similarity(vec, centroid_real)[0][0]\n",
    "    return 1 if sim_satire > sim_real else 0\n",
    "\n",
    "centroid_times = measure_time(predict_centroid_single, timing_samples)\n",
    "timing_results['Embedding + Centroid'] = {\n",
    "    'avg': np.mean(centroid_times),\n",
    "    'std': np.std(centroid_times),\n",
    "    'times': centroid_times\n",
    "}\n",
    "print(f\"Average: {timing_results['Embedding + Centroid']['avg']:.4f} ms\")\n",
    "print(f\"Std Dev: {timing_results['Embedding + Centroid']['std']:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring Embedding + LR...\n",
      "  Sample 1: 13.6774 ms (warmup - excluded)\n",
      "  Sample 1: 8.9905 ms\n",
      "  Sample 2: 8.9347 ms\n",
      "Average: 8.8771 ms\n",
      "Std Dev: 0.0583 ms\n"
     ]
    }
   ],
   "source": [
    "# Measure Embedding + LR\n",
    "print(\"\\nMeasuring Embedding + LR...\")\n",
    "\n",
    "def predict_lr_single(headline):\n",
    "    vec = sbert_model.encode([headline], show_progress_bar=False)\n",
    "    return lr_clf.predict(vec)[0]\n",
    "\n",
    "lr_times = measure_time(predict_lr_single, timing_samples)\n",
    "timing_results['Embedding + LR'] = {\n",
    "    'avg': np.mean(lr_times),\n",
    "    'std': np.std(lr_times),\n",
    "    'times': lr_times\n",
    "}\n",
    "print(f\"Average: {timing_results['Embedding + LR']['avg']:.4f} ms\")\n",
    "print(f\"Std Dev: {timing_results['Embedding + LR']['std']:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring LLM Zero-shot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample 1: 1391.4599 ms (warmup - excluded)\n",
      "  Sample 1: 1396.0791 ms\n",
      "  Sample 2: 1411.0849 ms\n",
      "Average: 1398.7692 ms\n",
      "Std Dev: 6.4722 ms\n"
     ]
    }
   ],
   "source": [
    "# Measure LLM Zero-shot\n",
    "print(\"\\nMeasuring LLM Zero-shot...\")\n",
    "llm_zero_times = measure_time(query_zeroshot, timing_samples)\n",
    "timing_results['LLM Zero-shot'] = {\n",
    "    'avg': np.mean(llm_zero_times),\n",
    "    'std': np.std(llm_zero_times),\n",
    "    'times': llm_zero_times\n",
    "}\n",
    "print(f\"Average: {timing_results['LLM Zero-shot']['avg']:.4f} ms\")\n",
    "print(f\"Std Dev: {timing_results['LLM Zero-shot']['std']:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring LLM Few-shot...\n",
      "  Sample 1: 2003.9020 ms (warmup - excluded)\n",
      "  Sample 1: 2005.9826 ms\n",
      "  Sample 2: 2080.8322 ms\n",
      "Average: 2017.2154 ms\n",
      "Std Dev: 21.4481 ms\n"
     ]
    }
   ],
   "source": [
    "# Measure LLM Few-shot\n",
    "print(\"\\nMeasuring LLM Few-shot...\")\n",
    "llm_few_times = measure_time(query_fewshot, timing_samples)\n",
    "timing_results['LLM Few-shot'] = {\n",
    "    'avg': np.mean(llm_few_times),\n",
    "    'std': np.std(llm_few_times),\n",
    "    'times': llm_few_times\n",
    "}\n",
    "print(f\"Average: {timing_results['LLM Few-shot']['avg']:.4f} ms\")\n",
    "print(f\"Std Dev: {timing_results['LLM Few-shot']['std']:.4f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPUTATIONAL EFFICIENCY (Table 3 from report)\n",
      "======================================================================\n",
      "Method                      Avg Time (ms)    Std Dev (ms)  Relative Speed\n",
      "----------------------------------------------------------------------\n",
      "Naive Baseline                      0.030           0.006              1x\n",
      "Embedding + Centroid               10.383           2.017            351x\n",
      "Embedding + LR                      8.877           0.058            301x\n",
      "LLM Zero-shot                    1398.769           6.472          47352x\n",
      "LLM Few-shot                     2017.215          21.448          68287x\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display timing comparison table\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPUTATIONAL EFFICIENCY (Table 3 from report)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<25} {'Avg Time (ms)':>15} {'Std Dev (ms)':>15} {'Relative Speed':>15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "baseline_time = timing_results['Naive Baseline']['avg']\n",
    "\n",
    "for method, data in timing_results.items():\n",
    "    relative = data['avg'] / baseline_time\n",
    "    print(f\"{method:<25} {data['avg']:>15.3f} {data['std']:>15.3f} {relative:>14.0f}x\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
